\chapter{Нелинейная и выпуклая оптимизация}







\section{Введение в нелинейную оптимизацию}

\subsection{Постановка задача нелинейной оптимизации}

    Общая постановка задачи нелинейной оптимизации очень проста и
    состоит в следующем. Пусть нам
    заданы \emph{допустимое множество} $\st{D}$ (его элементы называют
    допустимыми векторами, допустимыми точками или допустимыми планами ?????) и
    \emph{целевая функция} $f(\vc{x})$, определенная на множестве
    $\st{D}\subset\R^{n}$ или на некотором множестве $\st{X}\subset\R^{n}$,
    содержащем $\st{D}$. Требуется найти точку экстремума, т.е.
    точку минимума или точку максимума
    функции $f(\vc{x})$ на  множестве $\st{D}$. Про это множество
    предполагается, что оно задается с помощью системы уравнений и
    неравенств. При этом допускается, что либо целевая функция, либо
    некоторые из функций, задающих соответствующие уравнения или
    неравенства, являются нелинейными.

    Мы еще раньше договорились (?????) записывать задачу на минимум в виде
\begin{equation}
    \label{nel-zad-min}
    f(\vc{x})\rightarrow\min, \ \vc{x}\in\st{D},
\end{equation}
    а задачу на максимум --- в виде
\begin{equation}
    \label{nel-zad-max}
    f(\vc{x})\rightarrow\max, \ \vc{x}\in\st{D}.
\end{equation}



    Необходимо подчеркнуть, что само понятие \emph{точки максимума}
    (\emph{точки минимума}) неоднозначно и требует уточнения.

    Точка $\vc{x^{*}}\in\st{D}$ называется:
\begin{enumerate}
  \item точкой \emph{глобального максимума} (\emph{минимума}) функции $f(\vc{x})$
    на множестве $\st{D}$, если
    \[f(\vc{x^{*}})\geqslant f(\vc{x}) \ \forall \vc{x}\in\st{D}\]
    \[(f(\vc{x^{*}})\leqslant f(\vc{x}) \ \forall \vc{x}\in\st{D});\]
  \item точкой \emph{локального максимума} (\emph{минимума}) функции $f(\vc{x})$
    на множестве $\st{D}$, если существует число $\epsilon>0$, такое что
    \[f(\vc{x^{*}})\geqslant f(\vc{x}) \
    \forall \vc{x}\in\st{D}\cap\mathcal{U}_{\epsilon}(\vc{x^{*}})\]
    \[(f(\vc{x^{*}})\leqslant f(\vc{x}) \
    \forall \vc{x}\in\st{D}\cap\mathcal{U}_{\epsilon}(\vc{x^{*}})),\]
    где $\mathcal{U}_{\epsilon}(\vc{x^{*}})
    =\{\vc{x}\in\R^{n}\mid \|\vc{x}-\vc{x^{*}}\|<\epsilon\}$ ---
    $\epsilon$-окрестность точки $\vc{x^{*}}$, т.е.
    открытый шар радиуса $\epsilon>0$ с центром в $\vc{x^{*}}$.
\end{enumerate}




    Точку локального максимума или минимума иногда удобно называть
    \emph{локальным решением} задачи на максимум или  минимум соответственно.

    Ясно, что глобальный максимум (минимум) является и локальным.
    Обратное утверждение неверно, ибо точка локального максимума
    (минимума) может не быть точкой глобального максимума (минимума).

    \emph{Далее всегда, если не оговорено противное, под решением задачи
    на максимум или минимум мы будем понимать точку
    глобального максимума или минимума соответственно.}


    Задача на минимум преобразуется в задачу на максимум простым
    умножением целевой функции на $-1$. Поэтому, проявляя некоторую
    осторожность, теорию задач на минимум можно свести к теории
    задач на максимум. В дальнейшем мы, как правило, будем
    рассматривать задачи на максимум.


\subsection{Задача безусловной максимизации}
    Задача безусловной максимизации --- это такая задача вида
    (\ref{nel-zad-max}), для которой $\st{D}=\R^{n}$, т.е. задача

\begin{equation}
\label{nel-zad-bez}
    f(\vc{x})\rightarrow\max, \ \vc{x}\in\R^{n}.
\end{equation}



    В случае, когда речь идет о максимизации функции одной
    переменной, необходимым условием максимума дифференцируемой
    функции является равенство производной нулю. Нет ничего
    удивительного в том, что аналогичное утверждение верно и в более
    общем случае. Напомним, что вектор-градиентом или просто
    градиентом $\nabla f(\vc{x})$
    функции $f(\vc{x})$ в точке $\vc{x}=(x_{1},...,x_{n})$
    называется вектор частных производных:
    \[\nabla f(\vc{x})=
    \left(\frac{\partial f}{\partial x_{1}}(\vc{x}),...,
    \frac{\partial f}{\partial x_{n}}(\vc{x})\right).\]

    Далее всегда использование обозначения градиента будет
    автоматически означать, что все частные производные существуют.
    Напомним также, что для функций нескольких переменных понятие
    дифференцируемости не эквивалентно существованию частных
    производных. А именно, дифференцируемость (?????) функции в некоторой
    точке влечет существование частных производных, но не наоборот.
    Возможна ситуация, когда функция имеет в некоторой точке все
    частные производные, но не дифференцируема в этой точке. В тоже
    время, если все частные производные некоторой функции
    $f(\vc{x})$ определены в некоторой $\epsilon$-окрестности точки
    $\vc{x^{*}}$ и непрерывны в этой окрестности, то функция
    $f(\vc{x})$ дифференцируема в точке $\vc{x^{*}}$.

    Скажем несколько слов по поводу содержательного смысле понятия
    дифференцируемости функции нескольких переменных. Тот факт, что
    функция дифференцируема $f(\vc{x})$ в точке $\vc{x^{*}}$
    означает, что найдется такая линейная функция $A(\vc{h})$
    векторного аргумента $\vc{h}$, такая что поведение функции
    $f(\vc{x})$ в окрестности точки $\vc{x^{*}}$ достаточно хорошо
    аппроксимируется функцией
    $g(\vc{x})=f(\vc{x^{*}})+A(\vc{x}-\vc{x^{*}})$.
    Иными словами, если вектор $\vc{h}$ невелик по норме
    (?????), то (достаточно хорошо) выполняется приближенное равенство
    \[f(\vc{x^{*}}+\vc{h})-f(\vc{x^{*}})\approx A(\vc{h}).\]

    Как мы знаем, линейная функция $A(\vc{h})$
    векторного аргумента $\vc{h}$ однозначно задается некоторым
    $n$-мерным вектором $\vc{a}$ в том смысле, что $A(\vc{h})=\vc{a}\vc{h}$.
    Читатель, несомненно  помнит что в
    рассматриваемом случае этим вектором является вектор-градиент:
    $\vc{a}=\nabla f(\vc{x^{*}})$. Это означает, что справедливо следующее
    приближенное равенство
    \[f(\vc{x^{*}}+\vc{h})-f(\vc{x^{*}})\approx \nabla f(\vc{x^{*}})\vc{h}.\]
    Если бы мы были аккуратистами и использовали
    матричные обозначения, то мы обязательно подчеркнули, что в этой
    записи $\nabla f(\vc{x^{*}})$ --- это вектор-строка, а
    $\vc{x^{*}}$ и $\vc{h}$ --- вектор-столбцы.


\begin{teo}
    Предположим, что функция $f(\vc{x})$ дифференцируема в точке
    $\vc{x^{*}}$ или хотя бы имеет в этой точке частные производные.
    Если эта точка является точкой локального или
    глобального максимума функции $f(\vc{x^{*}})$ на $\R_{n}$, то
    \[\nabla f(\vc{x^{*}})=\vc{0}.\]
\end{teo}
   \label{teo-f-mnog}
    \textbf{Доказательство.} Достаточно заметить, что
    \[\nabla f(\vc{x^{*}})=\vc{0} \Leftrightarrow
    \frac{\partial f}{\partial x_{i}}(\vc{x^{*}})=0, \ i=1,...,n,\]
    и сослаться на соответствующую теорему для функций одной
    переменной. $\blacksquare$


    Хотя доказательство теоремы \ref{teo-f-mnog} совсем просто,
    приведем важное рассуждение, объясняющее, почему эта
    теореме справедлива и опирающееся на то предположение, что
    функция $f(\vc{x})$ дифференцируема в точке
    $\vc{x^{*}}$, а не только имеет в ней частные производные.


    Сначала заметим, что если точка $\vc{x^{*}}$
    представляет собой точку локального максимума некоторой линейной
    функции $A(\vc{x})=\vc{a}\vc{x}$ на $\R^{n}$, то это означает, что
    $\vc{a}\neq\vc{0}$. Действительно, в
    противном случае в любой сколь угодно малой окрестности точки
    $\vc{x^{*}}$ нашлась бы точка $\vc{x}$, для которой мы имели бы
    $\vc{a}\vc{x}>\vc{a}\vc{x^{*}}$.


    Теперь объясним, почему в точке $\vc{x^{*}}$ локального
    максимума функции $f(\vc{x})$ на $\R^{n}$ градиент
    $\nabla f(\vc{x^{*}})$ не может быть ненулевым.

    Предположим, что
    $\nabla f(\vc{x^{*}})\neq\vc{0}$. В этом случае в сколь угодно
    малой окрестности точки $\vc{x^{*}}$ найдется вектор $\vc{x}$,
    такой что
    $\nabla f(\vc{x^{*}})(\vc{x}-\vc{x^{*}})
    =\nabla f(\vc{x^{*}})\vc{x}-\nabla f(\vc{x^{*}})\vc{x^{*}}>0$.
    Если  окрестность действительно мала, то  приближенное
    равенство
    \[f(\vc{x})-f(\vc{x^{*}})\approx\nabla f(\vc{x^{*}})(\vc{x}-\vc{x^{*}})\]
    является достаточно точным. А отсюда следует, что
    $f(\vc{x})-f(\vc{x^{*}})>0$, т.е. точка
    $\vc{x^{*}}$ не является точкой локального максимума.

    Читатель, несомненно, обратил внимание на то, что равенство
    градиента нулю представляет собой необходимое условие максимума,
    но не достаточное. Точка, в которой градиент равен нулю может
    быть и точкой локального максимума, и точкой локального
    минимума, а может быть ни той и ни другой. Можно сформулировать
    достаточные условия максимума второго порядка
    (в терминах матрицы вторых производных), но это выходит за рамки
    нашего рассмотрения.

    И еще одно важное замечание. Равенство
    $\nabla f(\vc{x^{*}})=\vc{0}$ является необходимым условием
    локального максимума не только в том случае, когда допустимым
    множеством является все пространство $\R^{n}$. Важно только,
    чтобы точка $\vc{x^{*}}$ была внутренней точкой допустимого
    множества. А именно, имеет место следующая теорема.

\begin{teo} \label{nul-grad-neobh}
    Предположим, что функция $f(\vc{x})$ дифференцируема в точке
    $\vc{x^{*}}$, представляющей собой внутреннюю точку множества
    $\st{D}\subset\R^{n}$. Если эта точка является точкой локального
    максимума функции $f(\vc{x^{*}})$ на $\st{D}$, то
    \[\nabla f(\vc{x^{*}})=\vc{0}.\]
\end{teo}


\subsection{Классическая задача на условный экстремум}

    Классической задачей на условный экстремум называется задача
(\ref{nel-zad-min}) на минимум или задача
    (\ref{nel-zad-max}) на максимум, для которой допустимое множество задается
    системой конечного числа уравнений:
    \[\st{D}=\{\vc{x}\in\st{X} \ | \ g_{1}(\vc{x})=b_{1},...,g_{m}(\vc{x})=b_{m}\},\]
    где $\st{X}\subset\R^{n}$.
    Ограничим не умаляя общности наше рассмотрение задачей на условный максимум.
    Ее естественно записать в виде
\[
    f(\vc{x})\rightarrow\max,
\]
\[
    g_{j}(\vc{x})=b_{j}, \ j=1,...,m,
\]
\[
    \vc{x}\in\st{X}.
\]

    Иногда при записи этой задачи включение $\vc{x}\in\st{X}$
     опускают как самоочевидное.


    Приведем классическую теорему о необходимых условиях
    оптимальности для рассматриваемой задачи, известную как правило множителей
    Лагранжа.

\begin{teo}
    \label{class-mno-la}
   Предположим, что функции $f(\vc{x}), \
    g_{1}(\vc{x}),...,g_{m}(\vc{x})$  непрерывно дифференцируемы (????) в
    точке $\vc{x^{*}}=(x^{*}_{1},...,x^{*}_{n})$, представляющую собой
    внутреннюю точку множества $\st{X}$, и что градиенты
    $\nabla g_{1}(\vc{x^{*}}),...,\nabla g_{m}(\vc{x^{*}})$
    линейно независимы. Если $\vc{x^{*}}$ --- локальное решение
    задачи на условный максимум, то существуют такие  числа
    $\lambda_{1},...,\lambda_{m}$, причем, заданные однозначным
    образом, что
\begin{equation}
    \label{razloj-grad}
    \nabla f(\vc{x^{*}})=\lambda_{1}\nabla g_{1}(\vc{x^{*}})+...
    +\lambda_{m}\nabla g_{m}(\vc{x^{*}}).
\end{equation}
\end{teo}

    Равенство (\ref{razloj-grad})
    говорит о том, в точке локального максимума градиент целевой
    функции разлагается в линейную комбинацию градиентов функций,
    задающих ограничения. Коэффициенты
    $\lambda_{1},...,\lambda_{m}$ этого разложения
    называются множителями Лагранжа.

    Сформулированные условия не могут
    рассматриваться как некоторый метод решения задачи на условный
    максимум. Более того, те же самые условия являются и необходимыми
    условиями локального минимума.
     В то же время, при некоторых обстоятельствах они могут
    все-таки помочь решить задачу на условный максимум, т.е. точку глобального
    условного максимума. Предположим,
    что ее решение существует. Это можно гарантировать, если,
    например, про допустимое множество, задаваемое системой уравнений, известно, что
    оно ограничено, а функции, фигурирующие в этой системе непрерывны.
    Если эти функции еще и дифференцируемы, то для решения задачи можно
    просто отыскать все
    точки, удовлетворяющие сформулированным необходимым условиям, а также точки,
    в которых градиенты функций, задающих ограничения, линейно
    зависимы, и выбрать из них ту,
    что доставляет наибольшее значение целевой функции. Именно это
    точка будет точкой глобального условного максимума максимума.

    Мы приведем аккуратное доказательство теоремы \ref{class-mno-la} чуть ниже, а сейчас
    попытаемся объяснить, почему оно верно по-существу. Пусть точка
    $\vc{x^{*}}$ --- локальное решение задачи на условный максимум.
    Удобства ради введем следующие обозначения:
    \[\vc{c}=\nabla f(\vc{x^{*}}),\]
    \[\vc{a^{j}}=\nabla g_{j}(\vc{x^{*}}), \ j=1,...,m.\]
    Тот факт, что функции
    $f(\vc{x}), \ g_{1}(\vc{x}),...,g_{m}(\vc{x})$
    дифференцируемы в точке $\vc{x^{*}}$ говорит нам о том, что в
    достаточно малой окрестности этой точки следующие приближенные
    равенства выполняются достаточно точно:
    \[f(\vc{x})\approx f(\vc{x^{*}})+\vc{c}(\vc{x}-\vc{x^{*}}),\]
    \[g_{j}(\vc{x})\approx g_{j}(\vc{x^{*}})+\vc{a^{j}}(\vc{x}-\vc{x^{*}}), \ j=1,...,m.\]
    При этом чем меньше окрестность, тем более точно выполняются эти
    равенства. Это дает нам надежду на то, что точка $\vc{x^{*}}$
    является решением задачи
    \[f(\vc{x^{*}})+\vc{c}(\vc{x}-\vc{x^{*}})\rightarrow\max,\]
    \[g_{j}(\vc{x^{*}})+\vc{a^{j}}(\vc{x}-\vc{x^{*}})=b_{j}, \ j=1,...,m,\]
    эквивалентной задаче
\begin{equation}
    \label{class-mno-la-app}
    \begin{array}{c}
        \vc{c}\vc{x}\rightarrow\max, \\
        \vc{a^{j}}\vc{x}=b_{j}', \ j=1,...,m,
      \end{array}
\end{equation}
        при
    \[b_{j}'=\vc{a^{j}}\vc{x^{*}}-g_{j}(\vc{x^{*}}), \ j=1,...,m.\]

    Оказывается, эта надежда вполне обоснована. Можно показать, что точка $\vc{x^{*}}$
    действительно является решением задачи (\ref{class-mno-la-app}).
    Здесь ключевую роль играет предположение о том, что градиенты
    $\nabla g_{1}(\vc{x^{*}}),...,\nabla g_{m}(\vc{x^{*}})$
    линейно независимы. А задачу вида (\ref{class-mno-la-app}) мы
    уже обсуждали в ?????. Ее решение существует тогда и только
    тогда, когда найдутся числа $\lambda_{1},...,\lambda_{m}$, такие
    что выполняется равенство
    \[\vc{c}=\lambda_{1}\vc{a^{1}}+...+\lambda_{m}\vc{a^{m}},\]
    причем, задаются эти числа однозначно.
    А само равенство представляет собой записанное в других обозначениях равенство
    (\ref{razloj-grad}).

    Теперь приведем формальное доказательство теоремы
    \ref{class-mno-la}. Оно обобщает рассуждение проведенное в ???? и
    опирается на теорему об обратной функции в следующей формулировке.

\begin{teo} [теорема о неявной функции]
    Пусть $\psi_{1}(x_{1},...,x_{s}),...,\psi_{s}(x_{1},...,x_{s})$
    --- набор из $s$ функций $s$ переменных, каждая из которых непрерывно
    дифференцируема в некоторой окрестности точки
    $\vc{x^{*}}=(x^{*}_{1},...,x^{*}_{s})$.
    Пусть при этом матрица
    \[\left(
        \begin{array}{ccc}
          \frac{\partial\psi_{1}}{\partial x_{1}} & ... & \frac{\partial\psi_{1}}{\partial x_{s}} \\
          ... & ... & ... \\
          \frac{\partial\psi_{s}}{\partial x_{1}} & ... & \frac{\partial\psi_{s}}{\partial x_{s}} \\
        \end{array}
      \right)
\]
    имеет ранг $s$, т.е. ее определить отличен от нуля. Тогда
    существуют такие $\epsilon>0$ и $\delta>0$, что для любого
    $\vc{y}$ из $\epsilon$-окрестности
    \[\mathcal{U}_{\epsilon}(\vc{y^{*}})=\{\vc{y}\in\R^{n} \ | \ \|\vc{y}-\vc{y^{*}}\|\}<\epsilon\]
     точки
    $\vc{y^{*}}=(y^{*}_{1},...,y^{*}_{s}),$
    задаваемой равенствами
    \[y^{*}_{1}=\psi_{1}(x^{*}_{1},...,x^{*}_{s}),...,y^{*}_{s}
    =\psi_{s}(x^{*}_{1},...,x^{*}_{s}),\]
    найдется вектор $\vc{x}=(x_{1},...,x_{s})$ из $\delta$-окрестности
    \[\mathcal{U}_{\delta}(\vc{x^{*}})=\{\vc{x}\in\R^{n} \ | \ \|\vc{x}-\vc{x^{*}}\|<\delta\}\]
    точки $\vc{x^{*}}$, такой что
    \[y_{1}=\psi_{1}(x_{1},...,x_{s}),...,y_{s}
    =\psi_{s}(x_{1},...,x_{s}),\]
    и при этом $\|\vc{x}-\vc{x^{*}}\|\rightarrow\vc{0}$, когда
    $\|\vc{y}-\vc{y^{*}}\|\rightarrow\vc{0}$.
\end{teo}



    \textbf{Доказательство теоремы \ref{class-mno-la}}.
    Предположим, что вектор $\vc{x^{*}}$ представляет собой решение задачи на условный
    максимум, но чисел $\lambda_{1},...,\lambda_{m}$, для которых
    выполняется равенство (\ref{razloj-grad}), не существует. Это значит, что что
    набор вектор-градиентов
    $\nabla f(\vc{x^{*}}), \ \nabla g_{1}(\vc{x^{*}}),...,\nabla g_{m}(\vc{x^{*}})$
    является линейно независимым, т.е. ранг матрицы
    \[\left(
        \begin{array}{ccc}
\frac{\partial f}{\partial x_{1}} & ... & \frac{\partial f}{\partial x_{n}} \\
\frac{\partial g_{1}}{\partial x_{1}} & ... & \frac{\partial g_{1}}{\partial x_{n}} \\
... & ... & ... \\
\frac{\partial g_{m}}{\partial x_{1}} & ... & \frac{\partial g_{m}}{\partial x_{n}} \\
        \end{array}
      \right)
\]
    равен $m+1$. Для определенности будем считать, что линейно независимы
    первые $m+1$ столбцов этой матрицы. Отсюда следует, что набор
    функций
\[\psi_{0}(x_{1},...,x_{m+1})=f(x_{1},...,x_{m+1},x^{*}_{m+2},...,x^{*}_{n}),\]
\[\psi_{1}(x_{1},...,x_{m+1})=g_{1}(x_{1},...,x_{m+1},x^{*}_{m+2},...,x^{*}_{n}),...,\]
\[\psi_{m}(x_{1},...,x_{m+1})=g_{m}(x_{1},...,x_{m+1},x^{*}_{m+2},...,x^{*}_{n})\]
    удовлетворяет условиям теоремы об обратной функции. По этой
    теореме найдется число $\epsilon_{0}>0$, обладающее тем
    свойством, что для любого $\epsilon\in(0,\epsilon_{0})$
    существуют такие числа $x_{1}(\epsilon), ...,
    x_{m+1}(\epsilon)$, обладающие тем свойством, что
\[f(x_{1}(\epsilon),...,x_{m+1}(\epsilon),x^{*}_{m+2},...,x^{*}_{n})=
f(x^{*}_{1},...,x^{*}_{m+1},x^{*}_{m+2},...,x^{*}_{n})+\epsilon,\]
\[g_{1}(x^{*}_{1}(\epsilon),...,x^{*}_{m+1}(\epsilon),x^{*}_{m+2},...,x^{*}_{n})=b_{1},...,\]
\[g_{m}(x^{*}_{1}(\epsilon),...,x^{*}_{m+1}(\epsilon),x^{*}_{m+2},...,x^{*}_{n})=b_{m},\]
    причем $x_{i}(\epsilon)\rightarrow x^{*}_{i}$ при
$\epsilon\rightarrow 0$ для всех $i=1,...,m+1$. Но это означает, что
    точка $\vc{x^{*}}$ не является локальным решением задачи на
    условный экстремум. Полученное противоречие показывает, что требуемые числа
    $\lambda_{1},...,\lambda_{m}$ существуют. Тот факт, что эти числа
    задаются единственным образом, вытекает из линейной независимости вектор-градиентов
    $\nabla g_{1}(\vc{x^{*}}),...,\nabla g_{m}(\vc{x^{*}})$. $\blacksquare$


\begin{exer}
    Решите следующие задачи (если они имеют решения):
    \[x_{1}^{2}+x_{2}^{2}\rightarrow\max(\min),\]
    \[ 3x_{1}+4x_{2}=1;\]
    \[-(x_{1}^{2}+x_{2}^{2}+x_{3}^{2})\rightarrow\max(\min),\]
    \[ x_{1}+x_{2}+x_{3}=1, \ x_{1}+x_{2}-x_{3}=1/2;\]
    \[x_{1}x_{2}^{2}x_{3}^{3}\rightarrow\max(\min),\]
    \[ x_{1}^{2}+x_{2}^{2}+x_{3}^{2}=1;\]
    \[p_{1}x_{1}+...+p_{n}x_{n}\rightarrow\min,\]
    \[\sum_{i=1}^{n}x_{i}^{\rho}=1, \ 0<\rho<1;\]
    \[p_{1}x_{1}+...+p_{n}x_{n}\rightarrow\min,\]
    \[x_{1}^{\alpha_{1}}x_{2}^{\alpha_{2}}\cdot...\cdot x_{n}^{\alpha_{n}}=1, \
    \alpha_{1}>0, ..., \alpha_{n}>0.\]
\end{exer}

    Важным предположением в сформулированной теореме \ref{class-mno-la} является
    требование линейной независимости градиентов
    $\nabla g_{1}(\vc{x^{*}}),...,\nabla g_{m}(\vc{x^{*}})$. Иногда
    его называют \emph{условиями регулярности}.
    В случае, когда они линейно зависимы, существование множителей
    Лагранжа, с помощью которых градиент целевой функции разлагается
    в линейную комбинацию градиентов функций, задающих ограничения,
    гарантировать нельзя.
\begin{exer}
    Решите задачу
\begin{equation}
    \begin{array}{c}
      x_{1}+x_{2}\rightarrow\max, \\
      x_{1}^{2}+x_{2}^{2}=1, \ x_{1}=1.
    \end{array}
\end{equation}
    Покажите, что в точке максимума градиент целевой функции не
    разлагается в линейную комбинацию градиентов функций, задающих
    ограничения.
\end{exer}



\subsection{Нелинейное программирование}

    Под задачей нелинейного программирования обычно понимается задача
    вида (\ref{nel-zad-min})
    (\ref{nel-zad-max}), для которой допустимое множество задается
    системой конечного числа уравнений и неравенств:
    \[\st{D}=\{\vc{x}\in\st{X} \ | \ g_{1}(\vc{x})=b_{1},...,g_{k}(\vc{x})=b_{k}, \
    g_{k+1}(\vc{x})\leqslant b_{k+1},...,g_{m}(\vc{x})\leqslant b_{m}\},\]
    где $\st{X}\subset\R^{n}$.
    Как и выше, ограничим наше рассмотрение задачей на максимум.
    Ее естественно записать в виде
\begin{equation}
\label{zad-np-rav-ner}
\begin{array}{c}
  f(\vc{x})\rightarrow\max, \\
  g_{j}(\vc{x})=b_{j}, \ j=1,...,k, \\
  g_{j}(\vc{x})\leqslant b_{j}, j=k+1,...,m, \\
  \vc{x}\in\st{X}.
\end{array}
\end{equation}

    При записи этой задачи включение $\vc{x}\in\st{X}$ тоже иногда
    опускается.

    Сделаем важных пару замечаний по поводу формулировки задачи
    математического программирования.

    Во-первых, следует подчеркнуть, что если для классической задачи на
    условный экстремум сформулированные выше необходимые условия локального
    максимума в точности
    совпадают с условиями локального минимума, то в данном случае
    это уже не так. Хотя, конечно, поскольку задачу на минимум функции $f(\vc{x})$
    можно записать как задачу на максимум с целевой функцией
    $-f(\vc{x})$, зная, как формулируются необходимые условия для
    задачи на максимум, читателю не составит труда сформулировать
    аналогичные условия для задачи на минимум.

    Во-вторых, если в ограничениях, задающих допустимое
    множество, обнаружится неравенство  вида $g_{j}(\vc{x})\geq b_{j}$,
    то не нужно пугаться, ибо его можно переписать в виде
    $-g_{j}(\vc{x})\leq -b_{j}$. Кроме того, заметим, что, формально
    говоря, уравнение $g_{j}(\vc{x})= b_{j}$ эквивалентно паре
    неравенств: $g_{j}(\vc{x})\geq b_{j}$ и $g_{j}(\vc{x})\leq b_{j}$,
    правда, далеко не всегда разумно записывать уравнение как пару
    неравенств.

    Чтобы сделать наше изложение простым, рассмотрим задачу, в
    которой присутствуют только ограничения в виде неравенств:
\begin{equation}
    \label{zad-np-ner}
    \begin{array}{c}
      f(\vc{x})\rightarrow\max, \\
      g_{j}(\vc{x})\leq b_{j}, \ j=1,...,m, \\
    \vc{x}\in\st{X}.
    \end{array}
\end{equation}

    Чтобы сформулировать для этой задачи необходимые условия оптимальности,
    аналогичные правилу множителей Лагранжа для классической задачи
    на условный экстремум, назовем для допустимого вектора $\vc{x}$
    ограничение \emph{активным}, если оно выполняется для этого вектора как
    равенство и \emph{пассивным}, если оно выполняется как строгое
    неравенство. Множество активных в точке $\vc{x}$ ограничений мы
    будем обозначать, как $B(\vc{x})$. Более точно, положим
    \[B(\vc{x})=\{j \ | \ g_{j}(\vc{x})=b_{j} \}.\]

\begin{teo}
    \label{np-mno-la}
   Предположим, что функции $f(\vc{x}), \
    g_{1}(\vc{x}),...,g_{m}(\vc{x})$  непрерывно дифференцируемы (????) в
    точке $\vc{x^{*}}=(x^{*}_{1},...,x^{*}_{n})$, представляющую собой
    внутреннюю точку множества $\st{X}$, и что набор
    вектор-градиентов
    $\nabla g_{j}(\vc{x^{*}}), \ j\in B(\vc{x^{*}}),$
    линейно независим. Если $\vc{x^{*}}$ --- локальное решение
    задачи (\ref{zad-np-ner}), то существуют такие  числа
    $\lambda_{1}\geq0,...,\lambda_{m}\geq0$,
    что
\begin{equation}
    \label{razloj-grad-np}
    \nabla f(\vc{x^{*}})=\lambda_{1}\nabla g_{1}(\vc{x^{*}})+...
    +\lambda_{m}\nabla g_{m}(\vc{x^{*}}),
\end{equation}
    причем
\begin{equation}
    \label{dop-nez-np}
    \lambda_{j}(b_{j}-g_{j}(\vc{x^{*}})), \ j=1,...,m.
\end{equation}
\end{teo}



    Множители $\lambda_{1}\geq0,...,\lambda_{m}\geq0$, фигурирующие
    в формулировке этой теоремы, как и в классической задаче на условный экстремум,
    называют множителями Лагранжа,
    а сформулированные в теореме условия оптимальности ---  условиями Куна-Таккера.
    Саму теорему часто тоже называют теоремой Куна-Таккера, однако, чаще
    это название применяется в контексте выпуклого программирования.
    Требование о том, что что набор вектор-градиентов
    $\nabla g_{j}(\vc{x^{*}}), \ j\in B(\vc{x^{*}}),$
    линейно независим, иногда называют \emph{\textbf{условием
    регулярности}}. Это требование является существенным в том смысле, что без условия
    такого типа гарантировать вывод теоремы нельзя, хотя, возможны и
    какие-то другие условия регулярности. Этот вопрос мы обсудим
    позднее (см. ?????).

    Укажем на две важные отличительные особенности этой теоремы по
    сравнению с правилом множителей Лагранжа
    для классической задачи на условный максимум.

    Во-первых, обратим внимание на то, что данная теорема говорит не
    только о существовании множителей Лагранжа, но и о том, что они
    неотрицательны. Это связано именно с тем, что
    ограничения записаны не в виде равенств, как это было в классической
    задаче, а в виде неравенств.

    Во-вторых, важную роль здесь играют условия (\ref{dop-nez-np}),
    называемые \emph{условиями дополняющей нежесткости}. Они
    говорят, что множители Лагранжа, соответствующие пассивным
    ограничениям, должны равняться нулю. Их эквивалентным образом
    можно записать в следующем виде:
    \[g_{j}(\vc{x^{*}})<b_{j}\Rightarrow\lambda_{j}=0.\]
    Поскольку вектор $\vc{x^{*}}$ является допустимым и для него
    выполняются неравенства $g_{j}(\vc{x^{*}})\leq b_{j}, \
    j=1,...,m,$ условия дополняющей нежесткости можно записать и
    так:
    \[\sum_{j=1}^{m}\lambda_{j}(b_{j}-g_{j}(\vc{x^{*}})).\]
    В необходимых условиях для классической задачи условия
    дополняющей нежесткости отсутствуют просто потому, что в них нет
    никакой надобности, ибо там пассивные ограничения просто
    отсутствуют.

\begin{exer}
    Покажите на примере, что в теореме \ref{np-mno-la} условие
    регулярности, состоящее в
    требовании линейной независимости набора вектор-градиентов
    $\nabla g_{j}(\vc{x^{*}}), \ j\in B(\vc{x^{*}}),$ является
    существенным.
\end{exer}

\begin{exer}
    Сформулируйте утверждение, аналогичное теореме \ref{np-mno-la}
    для задачи
    \[
\begin{array}{c}
      f(\vc{x})\rightarrow\min, \\
      g_{j}(\vc{x})\leq b_{j}, \ j=1,...,m, \\
    \vc{x}\in\st{X},
\end{array}
\]
    и для задачи
\[
\begin{array}{c}
      f(\vc{x})\rightarrow\min, \\
      g_{j}(\vc{x})\geq b_{j}, \ j=1,...,m, \\
    \vc{x}\in\st{X}.
\end{array}
\]
\end{exer}


    Мы не будем доказывать теорему \ref{np-mno-la}, а проведем
    некоторое <<правдоподобное>> рассуждение, аналогичное тому
    рассуждению, что мы уже проводили по поводу правила множителей
    Лагранжа применительно к классической задаче на условный
    экстремум, и поясняющее по-существу, почему теорема верна.


Пусть точка
    $\vc{x^{*}}$ --- локальное решение задачи (\ref{zad-np-ner}).
    Положим
    \[\vc{c}=\nabla f(\vc{x^{*}}),\]
    \[\vc{a^{j}}=\nabla g_{j}(\vc{x^{*}}), \ j=1,...,m.\]
    Поскольку функции
    $f(\vc{x}), \ g_{1}(\vc{x}),...,g_{m}(\vc{x})$
    дифференцируемы в точке $\vc{x^{*}}$,  в
    достаточно малой окрестности этой точки следующие приближенные
    равенства выполняются достаточно точно:
    \[f(\vc{x})\approx f(\vc{x^{*}})+\vc{c}(\vc{x}-\vc{x^{*}}),\]
    \[g_{j}(\vc{x})\approx g_{j}(\vc{x^{*}})+\vc{a^{j}}(\vc{x}-\vc{x^{*}}), \ j=1,...,m.\]

    Это дает нам основания полагать, что точка $\vc{x^{*}}$
    является решением задачи
    \[f(\vc{x^{*}})+\vc{c}(\vc{x}-\vc{x^{*}})\rightarrow\max,\]
    \[g_{j}(\vc{x^{*}})+\vc{a^{j}}(\vc{x}-\vc{x^{*}})\leq b_{j}, \ j=1,...,m,\]
    которая эквивалентна задаче
\begin{equation}
    \label{nl-mno-la-app}
    \begin{array}{c}
        \vc{c}\vc{x}\rightarrow\max, \\
        \vc{a^{j}}\vc{x}\leq b_{j}', \ j=1,...,m,
      \end{array}
\end{equation}
        при
    \[b_{j}'=b_{j}+\vc{a^{j}}\vc{x^{*}}-g_{j}(\vc{x^{*}}), \ j=1,...,m.\]

    При сделанных в теореме предположениях точка $\vc{x^{*}}$
    действительно является решением задачи (\ref{nl-mno-la-app}).
    Как и в случае классической задачи это действительно так благодаря тому, что градиенты
    $\nabla g_{j}(\vc{x^{*}}), \ j\in B(\vc{x^{*}}),$
    линейно независимы. Задачу вида (\ref{class-mno-la-app}) мы
    уже обсуждали в ?????. Точка $\vc{x^{*}}$ является ее решением  тогда и только
    тогда, когда найдутся числа $\lambda_{1}\geq0,...,\lambda_{m}\geq0$, такие
    что
    \[\vc{c}=\lambda_{1}\vc{a^{1}}+...+\lambda_{m}\vc{a^{m}}\]
    и выполняются условия дополняющей нежесткости
    \[\lambda_{j}(b_{j}'-\vc{a^{j}}\vc{x^{*}})=0, \ j=1,...,m.\]
    Именно эти условия, правда в других обозначениях, и приведены
    в теореме \ref{np-mno-la}.


    Вернемся к общей задаче (\ref{zad-np-rav-ner}) и сформулируем
    следующую теорему, обобщающую теоремы \ref{class-mno-la} и
    \ref{np-mno-la}. Она также приводится без доказательства.

    \begin{teo}
    \label{np-mno-la-rav-ner}
   Предположим, что функции $f(\vc{x}), \
    g_{1}(\vc{x}),...,g_{m}(\vc{x})$  непрерывно дифференцируемы (????) в
    точке $\vc{x^{*}}=(x^{*}_{1},...,x^{*}_{n})$, представляющую собой
    внутреннюю точку множества $\st{X}$, и что набор
    вектор-градиентов
    $\nabla g_{j}(\vc{x^{*}}), \ j\in B(\vc{x^{*}}),$
    линейно независим. Если $\vc{x^{*}}$ --- локальное решение
    задачи (\ref{zad-np-rav-ner}), то существуют такие  числа
    $\lambda_{1},...,\lambda_{k}, \lambda_{k+1}\geq0,...,\lambda_{m}\geq0$,
    что
\begin{equation}
    \label{razloj-grad-np}
    \nabla f(\vc{x^{*}})=\lambda_{1}\nabla g_{1}(\vc{x^{*}})+...
    +\lambda_{m}\nabla g_{m}(\vc{x^{*}}),
\end{equation}
    причем
\begin{equation}
    \label{dop-nez-np-1}
    \lambda_{j}(b_{j}-g_{j}(\vc{x^{*}})), \ j=k+1,...,m.
\end{equation}
\end{teo}


    По поводу формулировки этой теоремы следует сделать только несколько
    кратких замечаний. Как и выше, через $B(\vc{x^{*}})$ обозначено
    множество всех активных в точке $\vc{x^{*}}$ ограничений, т.е.
    ограничений, которые выполняются в виде точного равенства. К
    ним, очевидно, принадлежат все ограничения $j=1,...,k$.
    Множители Лагранжа $\lambda_{j}$, соответствующие этим
    ограничениям, могут принимать как положительные, так и
    отрицательные значения. А множители Лагранжа, соответствующие
    ограничениям, записанным в виде неравенства, должны быть
    неотрицательными, причем, для пассивных в очке решения
    ограничений, они равны нулю.

\begin{exer}
    Сформулируйте утверждение, аналогичное теореме
\ref{np-mno-la-rav-ner}, применительно к задаче
\[
\begin{array}{c}
  f(\vc{x})\rightarrow\min, \\
  g_{j}(\vc{x})=b_{j}, \ j=1,...,k, \\
  g_{j}(\vc{x})\leq b_{j}, j=k+1,...,m, \\
  g_{j}(\vc{x})\geq b_{j}, j=m+1,...,s, \\
  \vc{x}\in\st{X}.
\end{array}
\]
\end{exer}



\subsection{Анализ чувствительности в задачах условной оптимизации}

    До сих пор мы рассматривали задачу (\ref{zad-np-rav-ner}) в
    предположении, что правые части ограничений, т.е. числа $b_{j}, \
    j=1,...,m,$ являются заданными. В этом пункте мы обсудим вопрос
    о том, как будет меняться значение задачи с изменением этих
    чисел. Чтобы не возникало недопонимания, подчеркнем, что здесь мы
    будем вести речь именно о значении задачи, т.е. о значении
    целевой функции в точке глобального максимума. Мы будем
    рассматривать набор чисел $b_{j}, \ j=1,...,m,$ как вектор из
    пространства $\R^{m}$.



\begin{teo}
    \label{anal-chuvs}
    Предположим, что при некотором $\vc{\bar{b}}=(\bar{b}_{1},...,\bar{b}_{m})$,
    а также при всех $\vc{b}$ из некоторой открытой
    $\epsilon$-окрестности
    \[\mathcal{U_{\epsilon}(\vc{\bar{b}})}=
    \{\vc{b}\in\R^{m} \ | \ \|\vc{b}-\vc{\bar{b}}\|<\epsilon\}, \ \epsilon>0,\]
    вектора  $\vc{\bar{b}}$,
    задача (\ref{zad-np-rav-ner}) имеет единственное решение
    $\vc{x(\vc{b})}=(x_{1}(\vc{b}),...,x_{n}(\vc{b}))$, удовлетворяющее всем условиям теоремы
    \ref{np-mno-la}, причем для всех
    $\vc{b}\in\mathcal{U_{\epsilon}(\vc{\bar{b}})}$ множество
    активных ограничений $B(\vc{x(\vc{b})})$ одно и то же:
    $B(\vc{x(\vc{b})})=B(\vc{x(\vc{\bar{b}})})$. Предположим далее,
    для всех $i=1,...,n$ функции $x_{i}(\vc{b})$ дифференцируемы.
    Тогда значение
    \[v(\vc{b})=f(\vc{x(\vc{b})})\]
    задачи (\ref{zad-np-rav-ner}) является дифференцируемой функцией
    $\vc{b}$ и
\begin{equation}
    \label{marg-znach}
    \frac{\partial v}{\partial b_{j}}(\vc{\bar{b}})=\lambda_{j}, \ j=1,...,m,
\end{equation}
    где $\lambda_{j}, \ j=1,...,m,$ --- значение множителей Лагранжа
    при $\vc{b}=\vc{\bar{b}}$.
\end{teo}

    Ключевую роль в этой теореме играет предположение о том, что
    функции $x_{i}(\vc{b})$ являются дифференцируемыми. Существуют
    некоторые условия, которые гарантируют дифференцируемость, но мы
    приводить их здесь не будем.

 \textbf{Доказательство теоремы \ref{anal-chuvs}.} Заметив, что для пассивных
    ограничений ограничений утверждение теоремы очевидно, рассмотрим
    $j\in B(\vc{x}(\vc{\bar{b}}))$. Мы имеем:

\begin{multline*}
    \frac{\partial v}{\partial b_{j}}(\vc{\bar{b}})
    =\frac{\partial f}{\partial b_{j}}(\vc{x}(\vc{\bar{b}}))
    =\sum_{i=1}^{n}\frac{\partial f}{\partial x_{i}}(\vc{x}(\vc{\bar{b}}))
    \frac{\partial x_{i}}{\partial b_{j}}(\vc{\bar{b}}) \\
    =\sum_{i=1}^{n}\left(\sum_{k=1}^{m}\lambda_{k}
    \frac{\partial g_{k}}{\partial x_{i}}(\vc{x}(\vc{\bar{b}}))\right)
    \frac{\partial x_{i}}{\partial b_{j}}(\vc{\bar{b}})
    =\sum_{k=1}^{m}\lambda_{k}\sum_{i=1}^{n}
    \frac{\partial g_{k}}{\partial x_{i}}(\vc{x}(\vc{\bar{b}}))
    \frac{\partial x_{i}}{\partial b_{j}}(\vc{\bar{b}}) \\
    =\sum_{k\in B(\vc{x}(\vc{\bar{b}}))}
    \lambda_{j}\frac{\partial g_{k}}{\partial b_{j}}(\vc{\bar{b}}).
\end{multline*}
    При $k\in B(\vc{x}(\vc{\bar{b}}))$ для всех
    $\vc{b}\in\mathcal{U_{\epsilon}(\vc{\bar{b}}))}$
    справедливо равенство $g_{k}(\vc{x}(\vc{b}))=b_{k}$.
    Дифференцируя его по $b_{k}$, получаем:
\[\frac{\partial g_{k}}{\partial b_{j}}(\vc{x}(\vc{\bar{b}}))=
\left\{
\begin{array}{c}
        1, \ k=j, \\
        0, \ k\neq j.
      \end{array}
\right.
\]
    Отсюда и получаем требуемое равенство
    \[\frac{\partial v}{\partial b_{j}}(\vc{\bar{b}})=\lambda_{j}. \ \blacksquare\]


    Для тех читателей, которым показалось, что приведенное доказательство
    является слишком коротким и не достаточно прозрачным,
    мы проведем несложное, хотя и несколько громоздкое,
    <<правдоподобное>> рассуждение, объясняющее в
    чем здесь суть дела.

    Сначала заметим, что для всех
    $\vc{b}\in\mathcal{U_{\epsilon}(\vc{\bar{b}}))}$ вектор
    $\vc{x(\vc{b})})$ является решением задачи
\begin{equation}
    \label{zad-np-activ}
\begin{array}{c}
  f(\vc{x})\rightarrow\min, \\
  g_{j}(\vc{x})=b_{j}, \ j\in B(\vc{x}(\vc{\bar{b}})), \\
\end{array}
\end{equation}
    поскольку, по предположению,
    $B(\vc{x(\vc{b})})=B(\vc{x(\vc{\bar{b}})})$
    для любого $\vc{b}\in\mathcal{{U}}_{\epsilon}(\vc{\bar{b}})$.

    Положим
    \[\vc{c}=\nabla f(\vc{x}(\vc{\bar{b}})),\]
    \[\vc{a^{j}}=\nabla g_{j}(\vc{x}(\vc{\bar{b}})), \ j\in B(\vc{x}(\vc{\bar{b}})).\]



    В силу дифференцируемости функции $f(\vc{x})$ и функций
    $g_{j}(\vc{x}), \ j\in B(\vc{x}(\vc{\bar{b}})),$ в окрестности
    точки $\vc{x}(\vc{\bar{b}})$ они достаточно хорошо
    аппроксимируются, соответственно, функциями
    \[\vc{c}\vc{x}+(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))=
    f(\vc{x}(\vc{\bar{b}}))+\vc{c}(\vc{x}-\vc{x}(\vc{\bar{b}}))\]
    и
    \[\vc{a^{j}}\vc{x}+(g_{j}(\vc{x}(\vc{\bar{b}}))-\vc{a^{j}}\vc{x}(\vc{\bar{b}})=
    g_{j}(\vc{x}(\vc{\bar{b}}))+\vc{a^{j}}(\vc{x}-\vc{x}(\vc{\bar{b}})),
    \ j\in B(\vc{x}(\vc{\bar{b}})),\]
    причем, точка $\vc{x}(\vc{\bar{b}})$
    является при $\vc{b}(=(b_{1},...,b_{m}))=\vc{\bar{b}}(=(\bar{b}_{1},...,\bar{b}_{m}))$
    решением задачи
\begin{equation}
    \label{zad-np-activ-lin-app}
\begin{array}{c}
  \vc{c}\vc{x}+(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))\rightarrow\max, \\
  \vc{a^{j}}\vc{x}+(g_{j}(\vc{x}(\vc{\bar{b}}))-\vc{a^{j}}\vc{x}(\vc{\bar{b}})
    =b_{j}, \ j\in B(\vc{x}(\vc{\bar{b}})),
\end{array}
\end{equation}
    в которой, очевидно, вектором переменных является вектор $\vc{x}$.

    При $\vc{b}(=(b_{1},...,b_{m}))\neq\vc{\bar{b}}(=(\bar{b}_{1},...,\bar{b}_{m}))$
    решение $\vc{x'}(\vc{b}))$ задачи (\ref{zad-np-activ-lin-app}) не совпадает,
    вообще говоря, с вектором $\vc{x}(\vc{b}))$. Однако, справедливо приближенное равенство
    \[\vc{x}(\vc{\bar{b}}+\Delta\vc{b})\approx\vc{x'}(\vc{\bar{b}}+\Delta\vc{b}),\]
    которое выполняется достаточно точно при малых по норме векторах
    $\Delta\vc{b}=(\Delta b_{1},...,\Delta b_{m})$. При этом,
    напомним,
    $\vc{c}=\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\vc{a_{j}}$
    и, кроме того, для всех $j\in B(\vc{x'}(\vc{\bar{b}}))$ мы
    имеем:
    \[\vc{a_{j}}\vc{x'}(\vc{\bar{b}})=b_{j}, \
    \vc{a_{j}}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})=b_{j}+\Delta b_{j}.\]
    Отсюда следует, что справедлива следующая цепочка соотношений:
\begin{multline*}
    f(\vc{x}(\vc{\bar{b}}+\Delta\vc{b}))-f(\vc{x}(\vc{\bar{b}}))
\\
    \approx[\vc{c}\vc{x}(\vc{\bar{b}}+\Delta\vc{b})
    +(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))]
    -[\vc{c}\vc{x'}(\vc{\bar{b}})+(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))]
\\
    \approx[\vc{c}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})
    +(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))]
    -[\vc{c}\vc{x'}(\vc{\bar{b}})+(f(\vc{x}(\vc{\bar{b}}))-\vc{c}\vc{x}(\vc{\bar{b}}))]=
\\
    \vc{c}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})-\vc{c}\vc{x'}(\vc{\bar{b}}).
\end{multline*}
    При этом, напомним,
    $\vc{c}=\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\vc{a_{j}}$
    и, кроме того, для всех $j\in B(\vc{x'}(\vc{\bar{b}}))$ мы
    имеем:
    \[\vc{a_{j}}\vc{x'}(\vc{\bar{b}})=b_{j}, \
    \vc{a_{j}}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})=b_{j}+\Delta b_{j}.\]
    Следовательно,
\begin{multline*}
    \vc{c}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})-\vc{c}\vc{x'}(\vc{\bar{b}})
\\
    =\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\vc{a_{j}}\vc{x'}(\vc{\bar{b}}+\Delta\vc{b})
    -\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\vc{a_{j}}\vc{x'}(\vc{\bar{b}})
\\
    =\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\Delta b_{j}.
\end{multline*}
    Итак,
    \[f(\vc{x}(\vc{\bar{b}}+\Delta\vc{b}))-f(\vc{x}(\vc{\bar{b}}))
    \approx\sum_{j\in B(\vc{x'}(\vc{\bar{b}}))}\lambda_{j}\Delta b_{j},\]
    откуда и вытекает справедливость (\ref{marg-znach}).



    Теперь приведем формальное доказательство.




 \

\subsection{Стандартная модель поведения потребителя}

    Простейшим примером применения теории экстремальных задач
    является стандартная модель поведения потребителя. Мы тоже
    вкратце опишем эту модель.

    Рассмотрим некоторого условного потребителя, перед которым стоит
    задача выбора потребительского набора. Каждый такой набор
    задается вектором $\vc{x}\in\R^{n}$, где $n$ --- это количество
    различных видов благ, доступных нашему потребителю.
    Предполагается, что потребительские наборы, среди которых делает
    свой выбор потребитель, должны принадлежать некоторому
    потребительскому множеству $\st{X}\subset\R^{n}$. Это множество
    предполагается замкнутым и выпуклым. Обычно
    считают, что потребительским множеством является неотрицательный
    ортант $\R^{n}_{+}$, хотя иногда удобно предполагать и иное.

    На множестве $\st{X}$ задано отношение предпочтения
    $\succsim$. Запись $\vc{x}\succsim\vc{y}$ означает, что с точки
    зрения нашего потребителя набор благ, задаваемый вектором
    $\vc{x}\in\st{X}$, является не менее предпочтительным (не хуже), чем набор
    благ, задаваемый вектором $\vc{y}\in\st{X}$. Предполагается, что отношение
    предпочтения $\succsim$ является \emph{полным}, \emph{рефлексивным} и
    \emph{транзитивным}. Полнота отношения предпочтения означает,
    что для любых двух векторов $\vc{x}$ и $\vc{y}$ из $\st{X}$
    выполняется хотя бы одно из двух следующих соотношений:
    \[\vc{x}\succsim\vc{y} \ \text{или} \ \vc{y}\succsim\vc{x},\]
     при этом могут выполняться и оба соотношения, рефлексивность
     --- что для любого $\vc{x}\in\st{X}$ справедливо
     соотношение
     \[\vc{x}\succsim\vc{x}\]
    (набор $\vc{x}$ не хуже самого себя), а транзитивность --- что
    \[\{\vc{x}\succsim\vc{y} \ , \ \vc{y}\succsim\vc{z}\}
    \Rightarrow \vc{x}\succsim\vc{z}\]
    (если набор $\vc{x}$ не хуже набора $\vc{y}$, а набор $\vc{y}$ не хуже
    набора $\vc{z}$, то набор $\vc{x}$ не хуже набора $\vc{z}$).


    При заданном отношении (нестрогого) предпочтения $\succsim$ мы
    следующим образом определяем  отношение строгого  предпочтения
    $\succ$:
\begin{multline*}
    \vc{x}\succ\vc{y} \ \Leftrightarrow \text{выполняется соотношение} \
    \vc{x}\succsim\vc{y},\\
    \text{но не выполняется соотношение} \
     \vc{y}\succsim\vc{x},
\end{multline*}
    а также отношение безразличия $\sim$:
    \[\vc{x}\sim\vc{y} \Leftrightarrow \{\vc{x}\succsim\vc{y}, \ \vc{y}\succsim\vc{x}.\}\]

    Запись $\vc{x}\succ\vc{y}$ говорит, что вектор $\vc{x}$
    (строго) предпочтительнее, или просто лучше, вектора $\vc{y}$ с
    точки зрения рассматриваемого потребителя, а запись
    $\vc{x}\sim\vc{y}$ --- что эти векторы одинаково хороши для него.

\begin{exer}
    Предположим, что отношение предпочтения $\succsim$ является
    полным, рефлексивным и транзитивным. Следует ли отсюда, что
    отношение строгого предпочтения $\succ$ и отношение безразличия
    $\sim$
    удовлетворяют следующим свойствам:
\begin{itemize}
\item [$1)$\ ] \
    для любых двух векторов $\vc{x}$ и $\vc{y}$ из $\st{X}$
    выполняется хотя бы одно из двух следующих соотношений:
    $\vc{x}\succ\vc{y}$ или $\vc{y}\succ\vc{x}$;
\item [$2)$\ ] \
    для любого $\vc{x}\in\st{X}$ справедливо
     соотношение
     $\vc{x}\succ\vc{x}$;
\item [$3)$\ ] \
    $\{\vc{x}\succ\vc{y} \ , \ \vc{y}\succ\vc{z}\}
    \Rightarrow \vc{x}\succ\vc{z}$;
\item [$1')$\ ] \
    для любых двух векторов $\vc{x}$ и $\vc{y}$ из $\st{X}$
    выполняется хотя бы одно из двух следующих соотношений:
    $\vc{x}\sim\vc{y}$ или $\vc{y}\sim\vc{x}$;
\item [$2')$\ ] \
    для любого $\vc{x}\in\st{X}$ справедливо
     соотношение
     $\vc{x}\sim\vc{x}$;
\item [$3')$\ ] \
    $\{\vc{x}\sim\vc{y} \ , \ \vc{y}\sim\vc{z}\}
    \Rightarrow \vc{x}\sim\vc{z}$.

\end{itemize}


\end{exer}


    Обычно по поводу отношения предпочтения $\succsim$ кроме указанных выше
    делают и некоторые другие существенные предположения. В частности,
    предполагается, что оно \emph{непрерывно}:
    \begin{multline*}
     \text{для любого} \
    \vc{x}\in\st{X} \ \text{множества} \\ \{\vc{y}\in\st{X} \ | \
    \vc{y}\succsim\vc{x}\} \ \text{и} \ \{\vc{y}\in\st{X} \ | \
    \vc{x}\succsim\vc{y}\} \ \text{являются замкнутыми};
    \end{multline*}
    \emph{выпукло}:
    \[\text{для любого} \
    \vc{x}\in\st{X} \ \text{множество} \{\vc{y}\in\st{X} \ | \
    \vc{y}\succsim\vc{x}\} \ \text{является выпуклым};\]
    а также \emph{монотонно}:
    \[\vc{x}\gg\vc{y} \ \Rightarrow \ \vc{x}\succ\vc{y}.\]


    Работать непосредственно с отношениями предпочтения работать не
    всегда удобно. Поэтому их часто задают с помощью функции
    полезности. Будем говорить, что функция полезности
    $U:\st{X}\rightarrow \R\cup\{-\infty\}$ \emph{задает} или \emph{представляет}
    отношение предпочтение $\succsim$, заданное на множестве
    $\st{X}$, если
    \[\vc{x}\succsim\vc{y} \ \Leftrightarrow \ U(\vc{x})\geqslant U(\vc{y}),\]
    иными словами, если вектор $\vc{x}$ не хуже вектора $\vc{y}$ в
    смысле отношения предпочтения $\succsim$ в том и только том
    случае, когда вектор $\vc{x}$ доставляет не не меньшее значение
    функции полезности, чем вектор $\vc{y}$.

\begin{exer}
    Докажите, что если функция полезности $U:\st{X}\rightarrow \R\cup\{-\infty\}$
    задает отношение предпочтения $\succsim$, то
    \[\vc{x}\succ\vc{y} \ \Leftrightarrow \ U(\vc{x})> U(\vc{y}), \
    \vc{x}\sim\vc{y} \ \Leftrightarrow \ U(\vc{x})= U(\vc{y}).\]
\end{exer}


    Существует ли функция полезности, задающее то или иное отношение
    предпочтения? Положительный ответ на этот вопрос дает следующая
    теорема, допускающая разнообразные обобщения.

\begin{teop}
    Предположим, что отношение предпочтения $\succsim$ заданное на
    множестве $\R_{+}^{n}$, является полным, рефлексивным,
    транзитивным, монотонным и непрерывным. Тогда существует функция
    полезности $U:\R_{+}^{n}\rightarrow \R$, задающая это отношение
    предпочтения.
\end{teop}

    \textbf{Доказательство.} Обозначим $\vc{e}=(1,\ldots,1)$.
    Для того, чтобы построить
    искомую функцию полезности $U$, достаточно показать, что для
    любого вектора $\vc{x}\in \R_{+}^{n}$ найдется и единственно число
    $\lambda_{x}$, такое что $\vc{x}\sim\lambda_{x}\vc{e}$,
    и задать функцию $U$ посредством равенства
    \[U(\vc{x})=\lambda_{x}.\]
    Возьмем произвольную точку $\vc{x}\in \R_{+}^{n}$ и положим
    \[\st{A}_{x}=\{\lambda\geq0 \  | \ \lambda\vc{e}\precsim\vc{x}\}, \
    \st{B}_{x}=\{\lambda\geq0 \  | \ \lambda\vc{e}\succsim\vc{x}\}.\]
    Множество $\st{A}_{x}$ непусто, поскольку оно содержит $\vc{0}$.
    Множество $\st{B}_{x}$ тоже непусто, ибо, очевидно, найдется
     $\lambda>0$, такое что $\lambda\vc{e}\gg\vc{x}$ и, в силу
    монотонности отношения предпочтения $\succsim$,
    $\lambda\vc{e}\succ\vc{x}$.

    Положим
    \[\lambda_{x}^{1}=\sup\{\lambda \ | \ \lambda\in\st{A}_{x}\}, \
    \lambda_{x}^{2}=\inf\{\lambda \ | \ \lambda\in\st{B}_{x}\}\]
    и заметим, что если $0\leq\gamma<\lambda_{x}^{1}$, то $\gamma\in\st{A}_{x}$,
    а если $\gamma>\lambda_{x}^{2}$, то $\gamma\in\st{B}_{x}$.

    Докажем, что $\lambda_{x}^{1}\in\st{A}_{x}$.
    Рассмотрим последовательность
    $(\gamma_{k})_{k=1}^{\infty}$ элементов $\st{A}_{x}$, сходящуюся к
    $\lambda_{x}^{1}$. Мы имеем
    \[\gamma_{k}\vc{e}\precsim\vc{x}, \ k=1,2,\ldots .\]
    Последовательность векторов $(\gamma_{k}\vc{e})_{k=1}^{\infty}$
    сходится к вектору $\lambda_{x}^{1}\vc{e}$. В силу непрерывности
    отношения предпочтения $\succsim$ мы имеем
    $\lambda_{x}^{1}\vc{e}\in\st{A}_{x}$, откуда и вытекает требуемое.

    Аналогичным образом доказывается включение $\lambda_{x}^{2}\in\st{B}_{x}$.

    Теперь докажем, что $\lambda_{x}^{1}=\lambda_{x}^{2}$.

    Для этого
    сначала проверим, что не может выполняться неравенство
    $\lambda_{x}^{1}>\lambda_{x}^{2}$. Действительно, если бы такое
    неравенство выполнялось, то мы бы имели
    \[\lambda_{x}^{1}\vc{e}\gg\lambda_{x}^{2}\vc{e}\]
    и, с учетом монотонности отношения $\succsim$,
    \[\lambda_{x}^{1}\vc{e}\succ\lambda_{x}^{2}\vc{e},\]
    а одновременно
    \[\lambda_{x}^{1}\vc{e}\precsim\vc{x}\precsim\lambda_{x}^{2}\vc{e},\]
    чего быть не может.

    Не может выполняться и неравенство
    $\lambda_{x}^{1}<\lambda_{x}^{2}$. Если бы оно выполнялось, то
    при $\hat{\lambda}\in(\lambda_{x}^{1},\lambda_{x}^{2})$ мы бы
    имели:
    \[\hat{\lambda}\vc{e}\succsim\vc{x}\succsim\hat{\lambda}\vc{e}.\]
    Первое из этих соотношений выполнялось бы в силу выбора $\lambda_{x}^{1}$ и полноты
    отношения $\succsim$, а второе --- в силу выбора
     $\lambda_{x}^{2}$. Однако первое из них
     противоречит выбору $\lambda_{x}^{2}$ (ибо $\hat{\lambda}<\lambda_{x}^{2}$), а
     второе --- выбору $\lambda_{x}^{1}$ (ибо
     $\lambda_{x}^{1}<\hat{\lambda}$).
     Итак, требуемое $\lambda_{x}$ задается равенством
     \[\lambda_{x}=\lambda_{x}^{1}=\lambda_{x}^{2}.\]

     Мы оставляем читателю проверить, что функция $U$ действительно
     задает отношение предпочтения $\succsim$ и что она непрерывна.
     $\Box$

    Функция полезности однозначным образом задает отношение
    предпочтения, но это не означает, что отношение предпочтение
    задается некоторой однозначно определяемой функцией полезности.
    Действительно, если функция $U:\st{X}\rightarrow
    \R\cup\{-\infty\}$ полезности задает отношение предпочтения
    $\succsim$, то это же отношение предпочтение задается и
    функцией полезности $V:\st{X}\rightarrow
    \R\cup\{-\infty\}$, определяемой равенством
    \[V(\vc{x})=f(U(\vc{x})),\]
    где $f:\R\cup\{-\infty\}\rightarrow \R\cup\{-\infty\}$ ---
    некоторая монотонно возрастающая функция.


    Заметим, что если отношение предпочтения $\succsim$ является монотонно
    возрастающим, функция полезности, задающая это отношение тоже
    является монотонно возрастающей в следующем смысле:
    \[\{\vc{x}, \vc{y}\in\st{X}, \vc{x}\gg\vc{y}\}
     \Rightarrow U(\vc{x})>U(\vc{y}). \]
     Кроме того, если отношение предпочтения $\succsim$ выпукло, то
     задающая его функция полезности $U$ является квазивогнутой,
     т.е. для любого $\gamma\in\R$ множество $\{\vc{x}\in\st{X} \ | \
     U(\vc{x})\geqslant\gamma\}$ выпукло. Здесь важно подчеркнуть, что
     функция совсем необязательно будет вогнутой. Далеко не для
     всякого выпуклого отношения предпочтения найдется задающая его вогнутая
     функция полезности.

\begin{exer}
\label{monot-ut}
    Докажите, что если функция $U$ является монотонной, то
    она обладает следующим свойством:
    \[\vc{x}\leqq\vc{y}\Rightarrow U(\vc{x})\leqslant U(\vc{y}).\]
\end{exer}

     Далее мы всегда, говоря об отношении предпочтения, будем
     считать, что полно, транзитивно, рефлексивно, монотонно,
     выпукло и непрерывно, а говоря о функции полезности --- что она
     непрерывна, монотонна и квазивогнута (хотя будем налагать на них и какие-то другие
     требования).


\begin{exer}
\label{fun-polCD}
    Проверьте, что при заданных $a>0$ и $\alpha_{i}>0, \ i=1,\ldots,n,$
    следующие функции полезности задают одно и то же отношение предпочтения:
    \[U(\vc{x})=a\prod_{i=1}^{n}x_{i}^{\alpha_{i}};\]
    \[\tilde{U}(\vc{x})=a\prod_{i=1}^{n}x_{i}^{\alpha_{i}/\sum_{j=1}^{n}\alpha_{j}};\]
    \[\tilde{\tilde{U}}(\vc{x})=\sum_{i=1}^{n}\alpha_{i}\ln x_{i}.\]
\end{exer}

\begin{exer}
\label{fun-polCES}
    Проверьте, что при заданных $\rho<1, \ \rho\neq0,$ и
    $\alpha_{i}>0, \ i=1,\ldots,n,$ следующие функции полезности задают одно и то же
    отношение предпочтения:
     \[U(\vc{x})=\left(\sum_{i=1}^{n}\alpha_{i}x_{i}^{\rho}\right)^{1/\rho};\]
    \[\tilde{U}(\vc{x})=\sum_{i=1}^{n}\alpha_{i}\frac{x_{i}^{\rho}}{\rho}.\]
\end{exer}



    Предположим, что потребитель располагает некоторым неотрицательным доходом $M$,
     а также что цены на блага задаются ненулевым вектором
    $\vc{p}=(p_{1},\ldots,p_{n})\geq\vc{0}$. Предполагается, что рассматриваемый нами
    потребитель имеет возможность приобрести любой вектор благ
    $\vc{x}=(x_{1},\ldots,x_{n})$, принадлежащий
    потребительскому множеству $\st{X}$ и удовлетворяющий бюджетному
    ограничению
    \[\vc{p}\vc{x}=p_{1}x_{1}+\ldots+p_{n}x_{n}\leqslant M.\]
    Бюджетное ограничение
    говорит о том, что потребитель может потратить на приобретение
    различных благ сумму, не превосходящую его дохода. Множество
    \[\{\vc{x}\in\st{X} \ | \ \vc{p}\vc{x}\leqslant M\}\]
    будем называть \emph{бюджетным множеством} потребителя.

\begin{exer}
\label{ogr-budg}
    Предположим, что потребительское множество ограничено снизу в
    том смысле, что существует вектор
    $\vc{\underline{x}}\in\R^{n}$, такой что
    \[\vc{x}\in\st{X}\Rightarrow \vc{\underline{x}}\geqq\vc{x}.\]
    Покажите, что если $\vc{p}\gg\vc{0}$, то бюджетное множество
    является ограниченным.
\end{exer}

    Задача потребителя состоит в выборе на бюджетном
    множестве такого его элемента $\vc{x^{*}}$, который является
    наилучшим в смысле отношения
    предпочтения $\succsim$, т.е. обладающего следующим свойством:
    \[\vc{y}\in\{\vc{x}\in\st{X} \ | \ \vc{p}\vc{x}\leqslant M\}\Rightarrow\vc{y}\precsim\vc{x^{*}}.\]

    Существует ли такой $\vc{x^{*}}$? Ответ на этот вопрос совсем
    несложен если отношение предпочтения $\succsim$
    задается непрерывной функцией полезности $U$. Действительно, в
    этом случае задача
    потребителя сводится к простой оптимизационной задаче
\begin{equation}
\label{zad-ptreb}
    U(\vc{x})\rightarrow\max, \ \vc{x}\in\st{X},  \ \vc{p}\vc{x}\leqslant M,
\end{equation}
    в том смысле, что вектор $\vc{x^{*}}$ является наилучшим на бюджетном
    множестве в смысле отношения предпочтения $\succsim$ тогда и
    только тогда, когда он является решением задачи
    (\ref{zad-ptreb}).
    С учетом упражнения \ref{ogr-budg} в силу теоремы Вейерштрасса эта задача имеет
    решение в случае, когда $\vc{p}\gg\vc{0}$, а потребительское множество ограничено
    снизу, например совпадает с $\R^{n}_{+}$.

\begin{exer}
    Предположим, что потребительское множество ограничено снизу,
    $\vc{p}\gg\vc{0}$,  а отношение предпочтения $\succsim$
     удовлетворяет указанным выше стандартным предположениям.
     Докажите, что на бюджетном множестве найдется наилучший в
     смысле этого отношения предпочтения элемент, причем сделайте
     это без использования задающей его функции полезности.
\end{exer}




    Если же хотя бы одна
    координата вектора $\vc{p}=(p_{1},\ldots,p_{n})$ равна нулю, то
    и в случае, когда $\st{X}=\R^{n}_{+}$, задача (\ref{zad-ptreb})
    не имеет решения, например, если $M>0$, а функция обладает следующим
    свойством:
    \[\{\vc{0}\ll\vc{x}\leqq\vc{y}, \vc{x}\neq\vc{y}\}\Rightarrow U(\vc{x})<U(\vc{y}).\]
    Это последнее свойство является некоторым усилением условия
    монотонности, которое мы ввели выше. Здесь следует обратить внимание
    читателя на то, что
    соотношения $\vc{x}\leqq\vc{y}$ и $\vc{x}\neq\vc{y}$
    означают, что вектор $\vc{y}$ не меньше вектора $\vc{x}$ по
    каждой координате, а хотя бы по одной строго больше. Этим
    свойством обладают функции полезности, упомянутые в упражнениях
    \ref{fun-polCD} и \ref{fun-polCES}.

\begin{exer}
    Покажите на примере, что возможна ситуация, когда
    $\st{X}=\R^{n}_{+}$, некоторые координаты вектора
    $\vc{p}=(p_{1},\ldots,p_{n})$ равны нулю, но задача (\ref{zad-ptreb}) имеет
    решение при любом $M>0$.
\end{exer}

    Далее всегда, когда не оговорено противное, мы будем
    предполагать, что что $\st{X}=\R^{n}_{+}$, отношение
    предпочтения удовлетворяет всем перечисленным выше стандартным
    условиям и, следовательно, задается некоторой монотонной непрерывной
    квазивогнутой функцией полезности а под задачей потребителя
    будем понимать задачу
    \begin{equation}
\label{zad-potr}
    U(\vc{x})\rightarrow\max, \ \vc{x}\geqq\vc{0},  \ \vc{p}\vc{x}\leqslant M.
\end{equation}

\begin{exer}
    Докажите, что в точке решения $\vc{x^{*}}$ задачи (\ref{zad-potr})
    бюджетное ограничение выполняется как равенство:
    \[\vc{p}\vc{x^{*}}=M.\]
\end{exer}


\begin{exer}
    Предположим, что функция полезности является леонтьевской:
    \[U(\vc{x})=\min\{x_{1}/\hat{x}_{1},\ldots,x_{n}/\hat{x}_{n}\},\]
    где $\vc{\hat{x}}=(\hat{x}_{1},\ldots,\hat{x}_{n})$ --- это
    некоторый
    фиксированный неотрицательный вектор, задающий некоторую потребительскую
    корзину.
    Докажите, что значение задачи (\ref{zad-potr}) равно
    \[\frac{M}{\sum_{i=1}^{n}p_{i}\hat{x}_{i}},\]
    а вектор
    \[\frac{M}{\sum_{i=1}^{n}p_{i}\hat{x}_{i}}\vc{\hat{x}}\]
    является ее решением.
\end{exer}




\begin{exer}
    Предположим, что функция полезности $U$ положительно однородна
    первой степени:
    \[U(\lambda\vc{x})=\lambda U(\vc{x}), \ \forall\lambda\geqslant0, \forall\vc{x}\geqq\vc{0}.\]
    Покажите, что если $\vc{x^{*}}$ --- решение задачи потребителя
    (\ref{zad-potr}) при некотором $M=M_{1}>0$, то вектор
    $\frac{M_{2}}{M_{1}}\vc{x^{*}}$ является решением этой задачи при
    $M=M_{2}>0$. Покажите также, что если вектор $\vc{x^{*}}$
    является решением задачи потребителя при некотором $M>0$ и
    некотором векторе цен $\vc{p}=\vc{p_{1}}$, а $\lambda>0$, то вектор
    $\vc{x^{*}}/\lambda$ представляет собой решение задачи той же при
    $\vc{p}=\lambda\vc{p_{1}}$.
\end{exer}

    Теперь рассмотрим случай, когда функция полезности $U$ непрерывно
    дифференцируема. При этом, из контекста будет понятно на каком
    множестве она непрерывно дифференцируема. Но во всяком случае
    будем считать, что
    она непрерывно дифференцируема на внутренности множества
    $\R_{+}^{n}$, т.е. на множестве
    \[\R_{++}^{n}=\{\vc{x}\in \R^{n} \ | \ \vc{x}\gg\vc{0}\}.\]
    В этом случае к задаче потребителя применимы необходимые и
    достаточные условия оптимальности, которые сформулированы нами в
    ?????.

    В некоторых случаях мы можем с первого взгляда на задачу
    заметить, что решением, если оно существует, является строго
    положительный вектор, т.е. вектор, принадлежащий множеству
    $\R_{++}^{n}$. В этом случае необходимые и достаточные условия
    оптимальности формулируются очень просто.



\begin{exer}
    Покажите, что в случае, когда $M>0$, при
    всех функциях полезности, упомянутых в упражнениях
    \ref{fun-polCD} и \ref{fun-polCES},
    решением задачи потребителя может быть только строго
    положительный вектор.
\end{exer}


\begin{prop}
    \label{usl-opt-zad-potr}
    Вектор $\vc{x^{*}}\gg\vc{0}$ является решением задачи
    (\ref{zad-potr}) тогда и только тогда, когда существует число
    $\lambda>0$, такое что выполняются следующие равенства:
    \[\vc{p}\vc{x^{*}}=M,\]
    \[\nabla U(\vc{x^{*}})=\lambda\vc{p}.\]
\end{prop}

\begin{exer}
    Объясните, почему величину $\lambda$, фигурирющую в
    предложении \ref{usl-opt-zad-potr}, иногда называют предельной
    полезностью денег.
\end{exer}

    Заметим, что предложение \ref{usl-opt-zad-potr} можно следующим
    эквивалентным образом переформулировать без упоминания величины
    $\lambda$.

\begin{prop}
    \label{usl-opt-zad-potr-1}
    Вектор $\vc{x^{*}}\gg\vc{0}$ является решением задачи
    (\ref{zad-potr}) тогда и только тогда, когда выполняются следующие соотношения:
    \[\vc{p}\vc{x^{*}}=M,\]
    \[\frac{\frac{\partial U}{\partial x_{1}}(\vc{x^{*}})}{p_{1}}=
    \frac{\frac{\partial U}{\partial x_{2}}(\vc{x^{*}})}{p_{2}}=
    \ldots=\frac{\frac{\partial U}{\partial x_{n}}(\vc{x^{*}})}{p_{n}}>0.\]
\end{prop}

\begin{exer}
\label{CD-resh}
    Покажите, что при $\vc{p}\gg\vc{0}$ в случае, когда
    \[U(\vc{x})=\sum_{i=1}^{n}\alpha_{i}\ln x_{i}, \ \alpha_{i}>0, \
     i=1,\ldots,n, \ \sum_{i=1}^{n}\alpha_{i}=1,\]
     решением задачи потребителя (\ref{zad-potr}) является вектор
     $\vc{x^{*}}=(x^{*}_{1},\ldots,x^{*}_{n})$, задаваемый соотношениями
\begin{equation}
\label{CD-reshenie}
     x^{*}_{i}=\frac{\alpha_{i}M}{p_{i}}, i=1,\ldots,n.
\end{equation}
\end{exer}
    Соотношения (\ref{CD-reshenie}) следует запомнить. Они говорят о
    том, что в рассматриваемом в упражнении случае решение задачи
    потребителя устроено совсем просто: вне зависимости от цен, на
    приобретение блага $i$ затрачивается фиксированная доля
    $\alpha_{i}$ его дохода.

\begin{exer}
    Решите задачу (\ref{zad-potr}) при $\vc{p}\gg\vc{0}$ для
    следующих функций полезности:
    \[U(\vc{x})=a\prod_{i=1}^{n}x_{i}^{\alpha_{i}}, a>0, \ \alpha_{i}>0, \ i=1,\ldots,n;\]
    \[U(\vc{x})=\left(\sum_{i=1}^{n}\alpha_{i}x_{i}^{\rho}\right)^{1/\rho},
     \ \alpha_{i}>0, \ i=1,\ldots,n, \ 0\neq\rho<1;\]
    \[U(\vc{x})=\sum_{i=1}^{n}\alpha_{i}\frac{x_{i}^{\rho}}{\rho}, \
    \alpha_{i}>0, \ i=1,\ldots,n, \ 0\neq\rho<1.\]
\end{exer}


    Теперь сформулируем условия оптимальности для задачи потребителя, применимые и в более
    общем случае, когда ее решением может оказаться вектор с нулевыми
    координатами. Они тоже являются следствием
    ??????.

\begin{prop}
    \label{usl-opt-zad-potr-2}
    Точка $\vc{x^{*}}\geqq\vc{0}$, в которой функция $U$ непрерывно дифференцируема,
     является решением задачи
    (\ref{zad-potr}) тогда и только тогда, когда существует число
    $\lambda>0$, такое что выполняются следующие соотношения:
    \[\vc{p}\vc{x^{*}}=M,\]
    \[\nabla U(\vc{x^{*}})\leqq\lambda\vc{p},\]
    \[(\lambda\vc{p}-\nabla U(\vc{x^{*}}))\vc{x^{*}}=0.\]
\end{prop}

    В этом предложении последнее условие, представляющее собой
    условие дополняющей нежесткости, можно переписать в следующем
    виде:
\[x^{*}_{i}>0 \Rightarrow \frac{\partial U}{\partial x_{i}}(\vc{x^{*}})=\lambda p_{i},
    \ i=1,\ldots,n.\]

    Здесь следует сделать еще одно замечание по поводу предложения
    \ref{usl-opt-zad-potr-2}. Когда мы говорим о том, что функция $U$ непрерывно
    дифференцируема в точке $\vc{x^{*}}\geqq\vc{0}$, мы считаем,
    что эта функция определена на некотором выпуклом множестве,
    содержащем $\R_{+}^{n}$, для которого эта точка является
    внутренней.


\begin{exer}
    Докажите предложение \ref{usl-opt-zad-potr-2}, используя ?????, и переформулируйте
    его в виде, который не содержит упоминания $\lambda>0$.
\end{exer}



\begin{exer}
    Предполагая, что $\vc{p}\gg\vc{0}$, причем $p_{n}=1$, решите задачу (\ref{zad-potr})
    для следующих функций полезности:
    \[U(\vc{x})=a\sum_{i=1}^{n-1}\alpha_{i}\ln x_{i}+x_{n}, \ a>0, \ \alpha_{i}>0, \
     i=1,\ldots,n-1, \ \sum_{i=1}^{n-1}\alpha_{i}=1;\]
    \[U(\vc{x})=a\prod_{i=1}^{n-1}x_{i}^{\alpha_{i}}+x_{n}, \ a>0,
     \ \alpha_{i}>0, \ i=1,\ldots,n-1,  \ \sum_{i=1}^{n-1}\alpha_{i}=1.\]
\end{exer}

    Функция полезности $U$ вида
    \[U(\vc{x})=u(x_{1},\ldots,x_{n-1})+x_{n},\]
    где $u:\R^{n-1}_{+}\rightarrow\R$ --- вогнутая непрерывная
    функция,
    называется \emph{квазилинейной}. Она имеет естественную
    экономическую интерпретацию в предположении, что $p_{n}=1$.
    Величина $u(x_{1},\ldots,x_{n-1})$
    показывает, какую полезность извлекает потребитель из
    потребления некоторых $n-1$ некоторых видов благ в количествах
    $x_{1},\ldots,x_{n-1}$, а величина $x_{n}$ показывает объемы
    "потребления" условного $n$-го блага, представляющего собой ту
    сумму денег, которая тратится на остальные блага. При этом здесь
    неявно предполагается, что полезность $u(x_{1},\ldots,x_{n-1})$
    измеряется в денежных единицах. Такое предположение является
    крайне сильным, но очень удобным с аналитической точки зрения,
    особенно, если отказаться от требования переменной $x_{n}$, т.е.
    допустить, что потребитель может "залезать в долги".


\begin{exer}
    Предположим, что функция полезности является квазилинейной,
    $p_{n}=1$, а потребительским множеством является множество
    \[\vc{x}=\{(x_{1},\ldots,x_{n})\in\R^{n} \ | \ x_{i}\geqslant0, \ i=1,\ldots,n-1\}.\]
    Докажите, что вектор
    $\vc{x^{*}}=(x_{1}^{*},\ldots,x_{n}^{*})$ является
    решением задачи потребителя (\ref{zad-ptreb}) тогда и только
    тогда, когда вектор $(x_{1}^{*},\ldots,x_{n-1}^{*})$
    является решением задачи
    \[u(x_{1},\ldots,x_{n-1})-\sum_{i=1}^{n-1}p_{i}x_{i}\rightarrow\max, \
    x_{i}\geqslant0, \ i=1,\ldots,n-1,\]
    а также выполняется равенство
    \[x_{n}^{*}=M-\sum_{i=1}^{n-1}p_{i}x_{i}^{*}.\]
\end{exer}







\section{Выпуклое программирование}



\subsection{Теорема Куна-таккера для задач выпуклого программирования}

    Задача на максимум
\begin{equation*}
    f(\vc{x})\rightarrow\max, \ \vc{x}\in\st{D},
\end{equation*}
    или задача на минимум
\begin{equation*}
    f(\vc{x})\rightarrow\min, \ \vc{x}\in\st{D},
\end{equation*}
    называется задачей выпуклого программирования, если целевая функция
    $f(\vc{x})$ вогнута, если речь идет о поиске максимума, или
    выпукла, когда речь идет о поиске минимума, а допустимое
    множество $\st{D}$ задается как
\[
    \st{D}=\{\vc{x} \in \st{X}:  g_j (\vc{x}) \geqslant b_j,  j=1,\ldots,m\},
\]
    где $\st{X}\subset\R^{n}$ --- выпуклое множество, а
    функции $g_1(\vc{x}), \ldots, g_m(\vc{x})$
    вогнуты. Очевидно, что если
\[
    \st{D}=\{\vc{x} \in \st{X}:  g_j (\vc{x}) \leqslant b_j, j=1,\ldots,m\},
\]
    где $g_1(\vc{x}), \ldots, g_m(\vc{x})$ --- выпуклые функции, то речь
    тоже идет о задаче выпуклого программирования, поскольку
    неравенство $g_j (\vc{x}) \leqslant b_j$, где $g_j (\vc{x})$ ---
    это функция, можно переписать в виде $-g_j (\vc{x}) \geqslant -b_j$,
    где функция $-g_j (\vc{x})$, очевидно, является вогнутой.


    Определенности ради, сейчас мы будем рассматривать задачу
    выпуклого программирования, записанную в следующем виде:

\begin{equation}\label{problem:ZVPgeq}
    \left\{ \begin{array}{l}
         f(\vc{x}) \to \max  \\
        g_j (\vc{x}) \geqslant b_j, \ j = 1,\ldots,m,\\
        \vc{x} \in \st{X} \\
  \end{array} \right.
\end{equation}
    где целевая функция $f(\vc{x})$ и все функции $g_j (\vc{x}), \ j =
    1,\ldots,m,$ вогнуты, а множество $\st{X}$ выпукло.

Отметим следующий важный и легко проверяемый с учетом Предложения
\ref{teo:property_weak_optimal} факт.

\begin{prop}\label{prop:x_weakoptimal}
Если точка $\vc{\hat x}$ представляет собой решение
задачи~(\ref{problem:ZVPgeq}), то эта точка слабо оптимальна по
Парето в смысле набора функций $f(\vc{x}), g_1(\vc{x}), \ldots,
g_m(\vc{x})$ на множестве $\st{X}$ и, следовательно, найдутся
неотрицательные коэффициенты $q, p_1, \ldots, p_m$, не все
одновременно равные нулю, такие что она представляет собой решение
задачи
\[
\left\{ \begin{array}{l}
 p_{0} f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x}) \to \max  \\
 \vc{x} \in \st{X} \\
 \end{array} \right.
\]
\end{prop}


\begin{exer}
Предложите условия, при которых решение
задачи~(\ref{problem:ZVPgeq}) есть оптимальная по Парето точка.
\end{exer}

    В сформулированном предложении \ref{prop:x_weakoptimal} о коэффициентах
    $p_{0}, p_1, \ldots, p_m$ говорится, что они не все они равны нулю.
    Чтобы условия оптимальности оказались  содержательно
    интересными, нужно быть уверенными, что ненулевым является
    коэффициент $p_{0}$, стоящий перед целевой функцией задачи
    ~(\ref{problem:ZVPgeq}). В этом случае можно считать, что этот
    коэффициент равен единице и, следовательно, точка $\vc{\hat x}$
    представляет собой решение задачи
\[
\left\{ \begin{array}{l}
 f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x}) \to \max  \\
 \vc{x} \in \st{X} \\
 \end{array} \right.
\]

    По-видимому, читатель заметил сходство функции
    $f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x})$
    с функцией Лагранжа, которое, как мы вскоре увидим, здесь совсем не случайно.

    Условия, которые гарантируют нам, что коэффициент $q$ не равен
    нулю, называют условиями регулярности. Самым известным из них
    является \emph{\textbf{условие Слейтера}}, которое применительно
    к задаче ~(\ref{problem:ZVPgeq}) состоит в следующем:

    существует такой вектор $\vc{\bar x}\in\st{X}$, для
которого выполняются следующие неравенства:

\[
\left\{ \begin{array}{l}
 g_1(\vc{\bar x}) > b_1\\
 g_2(\vc{\bar x}) > b_2 \\
  \cdots  \\
 g_m(\vc{\bar x}) > b_m \\
 \end{array} \right.
\]

\begin{exer}
    Проверьте, что условие Слейтера эквивалентно любому из следующих двух условий
    регулярности:

    --- для каждого $j=1,\ldots,m$ существует такая точка
    $\vc{x}_j \in \st{X}$, что
\[
 g_j(\vc{x}_j) > b_j;
\]

    --- для
    любого вектора $\vc{p} \geq \vc{0}$  существует такой вектор
    $\vc{\bar x} \in \st{X}$, что:
\[
    p_1 g_1(\vc{\bar x}) + p_2 g_2(\vc{\bar x}) + \ldots + p_m
    g_m(\vc{\bar x}) > p_1 b_1 + p_2 b_2 + \ldots + p_m b_m.
\]
\end{exer}




    Сейчас мы готовы формулировать теорему Куна-Таккера для
    задачи выпуклого программирования (\ref{problem:ZVPgeq}).




\begin{teop}\label{Kuhn-T-Vip1}(Теорема Куна-Таккера)

    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPgeq}) выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}\in \st{X}$ представляет собой решение
    задачи~(\ref{problem:ZVPgeq}) тогда и только тогда, когда существуют такие
    неотрицательные коэффициенты $\hat p_1, \hat p_2 \ldots, \hat
    p_m$, что



\begin{enumerate}
\renewcommand{\theenumi}{(\arabic{enumi})}
\item точка $\vc{\hat x}$ является решением задачи

\begin{equation}\label{KT-Max}
\left\{ \begin{array}{l}
   f(\vc{x}) + \hat p_1 g_1(\vc{x})+ \ldots + \hat p_m g_m(\vc{x}) \to \max  \\
   \vc{x} \in \st{X} \\
 \end{array} \right.
\end{equation}


\item выполняются следующие условия:
\begin{equation}\label{dop-nezj-vp0}
    \hat p_j \,(g_j(\vc{\hat x}) - b_j)=0, \ j=1,\ldots,m.
\end{equation}

\end{enumerate}
\end{teop}


    Коэффициенты $\hat p_1, \hat p_2 \ldots, \hat p_m$, о
    существовании которых здесь идет речь в данной теореме,
    как и в других аналогичных ситуациях, называют множителями
    Лагранжа, двойственными оценками или коэффициентами
    Куна-Таккера. Что касается равенств (\ref{dop-nezj-vp0}), то
    читатель, несомненно помнит, что их называют
    условиями \textbf{\emph{дополняющей
    нежесткости}}. Они говорит о том, что если на
    оптимальном плане некоторое $j$-е неравенство выполняется как
    строгое ($f_j(\vc{\hat x}) > b_j$), то соответствующий ему
    коэффициент $p_j$ обязательно равен нулю. Их можно переписать в
    следующем виде:
\[g_j(\vc{\hat x}) > b_j \Rightarrow \hat p_j =0.\]

    Зачастую условия дополняющей нежесткости записывают в следующем
    эквивалентном виде:
\begin{equation}\label{dop-nezj-vp1}
    \sum_{j=1}^{m}\hat p_j \,(g_j(\vc{\hat x}) - b_j)=0,
\end{equation}
    или, в матричных обозначениях,
    \[\vc{\hat p} \cdot (\vc{g}(\vc{\hat x})- \vc{b})=0,\]
    где $\vc{\hat p}=(\hat p_{1},\ldots,\hat p_{m})$,
    $\vc{g}(\vc{\hat x})=(g_{1}(\vc{\hat x}),\ldots,g_{m}(\vc{\hat x}))$,
    $\vc{b}=(b_{1},\ldots,b_{m})$.

\begin{exer}
    Докажите, что для любого допустимого вектора $\vc{\hat x}$ и любого набора
    неотрицательных чисел $\hat p_{1},\ldots,\hat p_{m}$ условие
    (\ref{dop-nezj-vp0}) эквивалентно равенству
    (\ref{dop-nezj-vp1}).
\end{exer}



\begin{proof} Теоремы \ref{Kuhn-T-Vip1}.

    \textbf{Необходимость.}
    Пусть вектор $\vc{\hat x}$ является решением задачи (\ref{problem:ZVPgeq}). Положим
\[
    b_{0}=f(\vc{\hat x}).
\]


    Поскольку $\vc{\hat x}$ является решением
    задачи~(\ref{problem:ZVPgeq}), не существует ни одного такого
    вектора $\vc{x}\in\st{X}$, который удовлетворял бы набору
    неравенств
\[
\left\{
    \begin{array}{c}
      f(\vc{x})>b_{0} \\
      g_{1}(\vc{x})>b_{1} \\
      \ldots \\
      g_{m}(\vc{x})>b_{m}
    \end{array}
\right.
\]
    По Лемме~\ref{fund-lemma} существуют такие неотрицательные
коэффициенты $p_0, p_1, \ldots, p_m$, не все одновременно равные
нулю, что
\begin{multline}\label{KT-doc1}
 p_0 f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x})\leqslant \\
 \leqslant p_{0}b_{0}+p_{1}b_{1}+\ldots+p_{m}b_{m}
 \ \forall\vc{x} \in \st{X}.
\end{multline}
    Поскольку вектор $\vc{\hat{x}}$ является допустимым и в силу
    выбора $b_{0}$ мы имеем:
\[
    p_0 f(\vc{\hat{x}})=p_{0}b_{0},
    p_1 g_1(\vc{\hat{x}})\geqslant p_{1}b_{1},\ldots,p_m g_m(\vc{\hat{x}})
    \geqslant p_{m}b_{m}.
\]
    Следовательно,
\[
    p_0 f(\vc{\hat{x}}) + p_1 g_1(\vc{\hat{x}})+ \ldots + p_m g_m(\vc{\hat{x}})
    = p_{0}b_{0}+p_{1}b_{1}+\ldots+p_{m}b_{m}.
\]
    Отсюда вытекает, что
\begin{multline*}
    p_0 f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x})
    \leqslant \\
    \leqslant p_0 f_0(\vc{\hat{x}}) + p_1 g_1(\vc{\hat{x}})+ \ldots
    + p_m g_m(\vc{\hat{x}})
 \ \forall\vc{x} \in \st{X},
\end{multline*}
    т.е. вектор $\vc{\hat{x}}$ является решением задачи
\[
    p_0 f(\vc{x}) + p_1 g_1(\vc{x})+ \ldots
    + p_m g_m(\vc{x})\rightarrow\max, \ \vc{x} \in \st{X}.
\]




    Покажем, что выполнение условие Слейтера гарантирует нам неравенство
$p_0>0$. Предположим, что это не так, т.е. $p_0=0$. В этом случае
\[
 p_1 g_1(\vc{x})+ \ldots + p_m g_m(\vc{x})
 \leqslant p_{1}b_{1}+\ldots+p_{m}b_{m}
 \ \forall\vc{x} \in \st{X}.
\]
    В частности,
\[
 p_1 g_1(\vc{\bar{x}})+ \ldots + p_m g_m(\vc{\bar{x}})
 \leqslant p_{1}b_{1}+\ldots+p_{m}b_{m},
\]
    где $\vc{\bar{x}}\in \st{X}$ --- вектор, о котором идет речь в
    условии Слейтера. Напомним, что для него справедливы неравенства
\[
    g_1(\vc{\bar{x}})>b_{1},\ldots,g_m(\vc{\bar{x}})>b_{m}.
\]
    В силу этих неравенств и с учетом того факта, что хотя бы
    один из неотрицательных коэффициентов
    $p_{1},\ldots,p_{m}$ положителен, заключаем, что
\[
    p_1 g_1(\vc{\bar{x}})+ \ldots + p_m g_m(\vc{\bar{x}})
    > p_{1}b_{1}+\ldots+p_{m}b_{m}.
\]
    Это неравенство противоречит (\ref{KT-doc1}). Полученное противоречие
    показывает, что $p_{0}>0$.



    Теперь от противного докажем, что для точки $\vc{\hat x}$
    выполняются соотношения
\begin{equation} \label{KT-doc-dop-nezj}
    p_{j}(g_{j}(\vc{\hat{x}})-b_{j})=0, \ j=1,\ldots,m,
\end{equation}
    т.е. что $p_{j}=0$ для тех $j$, при которых
    $g_{j}(\vc{\hat{x}})>b_{j}$.
    Предположим, что это не так, т.е.
    для некоторого индекса $k$ одновременно выполняются неравенства
    $g_k(\vc{\hat{x}}) > b_k$ и $p_k >0$. Мы имеем:
\[
\left\{ \begin{array}{l}
 p_0 f(\vc{\hat x}) = p_0 b_0\\
 p_1 g_1(\vc{\hat x}) \geq p_1 b_1 \\
  \cdots  \\
 p_k g_k(\vc{\hat x}) > p_k b_k \\
  \cdots  \\
 p_m g_m(\vc{\hat x}) \geq p_m b_m \\
  \end{array} \right.
\]
Сложив соответственно левые и правые части этих неравенств, получаем
строгое неравенство:
\[ p_0 f(\vc{\hat x}) + p_1 g_1(\vc{\hat x}) + \ldots + p_m g_m(\vc{\hat x}) >
p_0 b_0 + p_1 b_1 + \ldots + p_m b_m,
\]
 которое противоречит (\ref{KT-doc1}). Это противоречие
 доказывает справедливость (\ref{KT-doc-dop-nezj}).





    Положив
\[
    \hat p_j=\frac{p_j}{p_0}, \ j=1,\ldots,m,
\]
    мы сразу же видим, что вектор $\vc{\hat x}$ представляет собой решение
    задачи (\ref{KT-Max}) и для него выполняется условие дополняющей нежесткости
    (\ref{dop-nezj-vp0}).

    \textbf{Достаточность.}
    Пусть допустимый вектор $\vc{\hat x}$ представляет собой решение
    задачи (\ref{KT-Max}), т.е.
\begin{multline}\label{KT-Max-2}
    f(\vc{x}) + \hat{p}_1 g_1(\vc{x})+ \ldots + \hat{p}_m g_m(\vc{x})
    \leqslant \\
    \leqslant f_0(\vc{\hat{x}}) + \hat{p}_1 g_1(\vc{\hat{x}})+ \ldots
    + \hat{p}_m g_m(\vc{\hat{x}})
 \ \forall\vc{x} \in \st{X},
\end{multline}
и для него выполняется условие дополняющей нежесткости
    (\ref{dop-nezj-vp0}).

    В силу того, что все числа $\hat{p}_{1},\ldots,\hat{p}_{m}$
    неотрицательны, для любого допустимого вектора $\vc{x}$
    справедливо неравенство
\[
    \hat{p}_1 g_1(\vc{x})+ \ldots + \hat{p}_m g_m(\vc{x})
    \leqslant \hat{p}_1 b_{1}+\ldots+\hat{p}_m b_m,
\]
    а поскольку вектор $\vc{\hat{x}}$ является допустимым и для него
    выполняются условия дополняющей нежесткости,
\[
    \hat{p}_1 g_1(\vc{\hat{x}})+ \ldots + \hat{p}_m g_m(\vc{\hat{x}})
    =\hat{p}_1 b_{1}+\ldots+\hat{p}_m b_m.
\]
    Следовательно, для любого допустимого вектора $\vc{x}$ мы имеем:
\[
    \hat{p}_1 g_1(\vc{\hat{x}})+ \ldots + \hat{p}_m g_m(\vc{\hat{x}})\geqslant
    \hat{p}_1 g_1(\vc{x})+ \ldots + \hat{p}_m g_m(\vc{x})
    \ \forall\vc{x} \in \st{X}.
\]
    Сложив это неравенство с неравенством (\ref{KT-Max-2}),
    заключаем, что каждый допустимый вектор $\vc{x}$ удовлетворяет
    неравенству
\[
    f(\vc{\hat{x}})\geqslant f(\vc{x}),
\]
    которое и говорит о том, что $\vc{\hat{x}}$ представляет собой
    решение рассматриваемой задачи выпуклого программирования.
\end{proof}

    \textbf{Замечание.} Как видно из доказательства, тот пункт
    теоремы Куна-Таккера, где идет речь о достаточности соответствующих условий
    оптимальности, не требует для своей справедливости ни
     условия Слейтера, ни выпуклости множества $\st{X}$, ни
     вогнутости функций $f(\vc{x}), g_1(\vc{x}), \ldots, g_m(\vc{x})$.


\begin{exer}
Покажите на примере существенность условия Слейтера в том пункте
теоремы Куна-Таккера, где говорится о необходимости сформулированных
условий оптимальности.
\end{exer}


    В содержательных экономических задачах выпуклого
    программирования на максимум ограничения естественно записывать
    не так, как в задаче (\ref{problem:ZVPgeq}), а в виде
\[
    g_j (\vc{x}) \leqslant b_j, \ j=1,\ldots,m,
\]
    где $g_j (\vc{x}), j=1,\ldots,m,$ --- выпуклые функции. Именно в
    таком виде удобно записывать, например, задачи о максимизации
    дохода фирмы при ограничениях на количество используемых
    ресурсов.

    Поэтому несомненно стоит сформулировать теорему Куна-Таккера к
    задаче выпуклого программирования, записанной в следующем виде:
\begin{equation}\label{problem:ZVPleq}
    \left\{ \begin{array}{l}
         f(\vc{x}) \to \max  \\
        g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,m,\\
        \vc{x} \in \st{X}, \\
  \end{array} \right.
\end{equation}
    где, естественно, функция $f(\vc{x})$ вогнута, функции
    $g_j (\vc{x}), \ j=1,\ldots,m,$ выпуклы, а $\st{X}$ --- это выпуклое
    множество. Применительно к данной задаче \emph{\textbf{условие
    Слейтера}} формулируется следующим образом:

    существует вектор $\vc{\bar{x}}\in\st{X}$, такой что
\begin{equation}
\label{Slater1}
    \left\{ \begin{array}{l}
        g_1(\vc{\bar x}) < b_1\\
        g_2(\vc{\bar x}) < b_2 \\
        \cdots  \\
        g_m(\vc{\bar x}) < b_m \\
    \end{array} \right.
\end{equation}


\begin{teop}\label{Kuhn-T-Vip2}(Теорема Куна-Таккера)

    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPleq}) выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}$ представляет собой решение
    задачи~(\ref{problem:ZVPleq}) тогда и только тогда, когда существуют такие
    неотрицательные коэффициенты $\hat p_1, \hat p_2 \ldots, \hat
    p_m$, что



\begin{enumerate}
\renewcommand{\theenumi}{(\arabic{enumi})}
\item точка $\vc{\hat x}$ является решением задачи
\begin{equation}\label{KT-Max1}
   f(\vc{x}) - (\hat p_1 g_1(\vc{x})+ \ldots + \hat p_m g_m(\vc{x}))
    \rightarrow\max, \ \vc{x}\in\st{X};
 \end{equation}
\item выполняются следующие условия дополняющей нежесткости:
\begin{equation}\label{dop-nezj-vp1}
    \hat p_j \,(b_j-g_j(\vc{\hat x}))=0, \ j=1,\ldots,m.
\end{equation}

\end{enumerate}
\end{teop}

    Обычно в задаче выпуклого программирования
    (\ref{problem:ZVPleq}) множество $\st{X}$ задается с помощью
    набора из нескольких неравенств, т.е. при некотором $r$ мы можем записать:
\[
    \st{X}=\{\vc{x}\in\R^{n} \mid g_j (\vc{x}) \leqslant b_j,
    \ j = m+1,\ldots,r\},
\]
    где $g_j (\vc{x}), \ j = m+1,\ldots,r,$ ---
    это некоторые выпуклые непрерывные функции.

    В этом случае задача (\ref{problem:ZVPleq}) выглядит следующим
    образом:
\begin{equation*}
    \left\{ \begin{array}{l}
         f(\vc{x}) \to \max  \\
        g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,r.\\
          \end{array} \right.
\end{equation*}
    Глядя на эту запись, становится понятным, что решать вопрос о том, с
    помощью каких из неравенств
    $g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,r,$
    задавать множество $\st{X}$, а какие из них оставить
    записанными в явном виде с
    тем чтобы приписывать им двойственные оценки,
    надо решать на основе некоторых содержательных соображений. Во
    всяком случае, говоря о двойственных оценках,  иногда следует в явном
    виде указывать, к каким ограничениям эти двойственные оценки
    относятся. Например, если рассматривается задача
\begin{equation*}
    \left\{
    \begin{array}{l}
         f(\vc{x}) \to \max  \\
        g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,m,\\
    \vc{x}\geqq\vc{0},
    \end{array} \right.
\end{equation*}
    то зачастую с помощью ограничения на неотрицательность
    $\vc{x}\geqq\vc{0}$ задают множество $\st{X}$, а говоря о
    двойственных оценках, имеют в виду двойственные оценки
    ограничений   $g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,m.$




    Иногда удобно использовать обозначение
\[
    \vc{g}(\vc{x})=(g_{1}(\vc{x}),\ldots,g_{m}(\vc{x})).
\]
    В этом случае задачу (\ref{problem:ZVPleq}) можно переписать в
    виде
\begin{equation}\label{problem:ZVPleq-vec}
    \left\{ \begin{array}{l}
         f(\vc{x}) \to \max  \\
        \vc{g}(\vc{x})\leqq \vc{b}\\
        \vc{x} \in \st{X}, \\
  \end{array} \right.
\end{equation}
    где $\vc{b}=(b_{1},\ldots,b_{m})$, набор соотношений (\ref{Slater1}) в виде
\[
    \vc{g}(\vc{x})\gg \vc{b},
\]
    задачу (\ref{KT-Max1}) в виде
\begin{equation}\label{KT-Max1-vec}
    f(\vc{x})-\vc{\hat{p}}\vc{g}(\vc{x})\rightarrow\max, \
    \vc{x}\in\st{X},
\end{equation}
    где $\vc{\hat{p}}=(p_{1},\ldots,p_{m})$,
    а условия дополняющей нежесткости (\ref{dop-nezj-vp1}) в виде
\begin{equation}\label{dop-nezj-vp1-vec}
    \vc{\hat{p}}(\vc{b}-\vc{g}(\vc{\hat{x}}))=0.
\end{equation}


    Традиционно теорема Куна-Таккера формулируется в терминах
    функции Лагранжа. Для задачи ~(\ref{problem:ZVPleq}) эта функция
    определяется следующим образом:
\[
    \mathcal{L}(\vc{x},\vc{p})
        =f(\vc{x})+\vc{p}(\vc{b}-\vc{g}(\vc{x})).
\]
    Она определена на множестве
    $\{(\vc{x},\vc{p})\in\R^{n+m}_{+} \mid \vc{x}\in\st{X}, \
    \vc{p}\in\R^{m}_{+}\}$.


    При заданном
    $\vc{\hat{p}}=(\hat{p}_{1},\ldots,\hat{p}_{m})$
    функция Лагранжа отличается от целевой функции в задаче
    (\ref{KT-Max1}) на константу:
\[
    \mathcal{L}(\vc{x},\vc{\hat{p}})=f(\vc{x})-\vc{p}\vc{g}(\vc{x}))+\vc{p}\vc{b},
\]
    причем если $\vc{b}=\vc{0}$, то различия вообще никакого
    нет. Следовательно, решение задачи (\ref{KT-Max1}) совпадает с
    решением задачи
\begin{equation}\label{max-fun-lag}
    \mathcal{L}(\vc{x},\vc{\hat{p}})\rightarrow\max, \
    \vc{x}\in\st{X},
\end{equation}
    а теорему \ref{Kuhn-T-Vip2} можно эквивалентным образом
    переформулировать следующим образом.

\begin{teop}\label{Kuhn-T-Vip3}(Теорема Куна-Таккера)

    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPleq-vec}) выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}\in \st{X}$ представляет собой решение
     этой задачи тогда и только тогда, когда существуют
    такой вектор $\vc{\hat{p}}\geqq\vc{0}$,
    что точка $\vc{\hat x}$ является решением задачи
    (\ref{max-fun-lag}) и выполняются условия дополняющей нежесткости
    (\ref{dop-nezj-vp1-vec}).
\end{teop}







    Иногда теорему Куна-Таккера формулируют как теорему о седловой
    точке функции Лагранжа, а именно, в следующем виде.
\begin{teop}\label{Kuhn-T-Vip4}(Куна-Таккера)

    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPleq-vec}) выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}\in \st{X}$ представляет собой
    решение этой
    задачи тогда и только тогда, когда существуют
    такой вектор $\vc{\hat{p}}\geqq\vc{0}$, что вектор
    $(\vc{\hat x},\vc{\hat p})$ является седловой
    точкой функции Лагранжа $\mathcal{L}(\vc{x},\vc{p})$, т.е.
    выполняются следующие соотношения:
\[
    \mathcal{L}(\vc{x},\vc{\hat{p}})
    \leqslant\mathcal{L}(\vc{\hat{x}},\vc{\hat{p}})
    \leqslant\mathcal{L}(\vc{\hat{x}},\vc{p}) \
    \forall  \vc{x}\in\st{X} \ \forall \vc{p}\geqq\vc{0}.
\]
\end{teop}

\begin{exer}
    Используя теорему \ref{Kuhn-T-Vip3}, докажите теорему
    \ref{Kuhn-T-Vip4}. Покажите также, что из утверждения теоремы
    \ref{Kuhn-T-Vip4} вытекает теорема \ref{Kuhn-T-Vip3}.
\end{exer}





    Теперь рассмотрим задачу (\ref{problem:ZVPleq}) в предположении,
    что как целевая функция $f(\vc{x})$, так и функции $g_{j}(\vc{x}), \
    j=1,\ldots,m,$ непрерывно дифференцируемы в точке решения.
    Запишем задачу (\ref{KT-Max1})  в следующем виде
\begin{equation}\label{KT-Max-3}
    \psi(\vc{x})\rightarrow\max, \ \vc{x}\in\st{X},
\end{equation}
    где
\[
    \psi(\vc{x})=f(\vc{x}) - (\hat p_1 g_1(\vc{x})+ \ldots + \hat p_m
    g_m(\vc{x})).
\]
    Функция очевидно,  $\psi(\vc{x})$ вогнута. В силу теоремы \ref{grad-nul}
    точка $\vc{\hat{x}}$, находящаяся во внутренности множества $\st{X}$,
    является решением задачи (\ref{KT-Max-2}) тогда и только тогда,
    когда
\[
    \nabla\psi(\vc{\hat{x}})=\vc{0},
\]
    т.е. когда
\[
    \nabla f(\vc{\hat{x}})
    - (\hat p_1 \nabla g_1(\vc{\hat{x}})+ \ldots + \hat p_m \nabla g_m(\vc{\hat{x}}))=\vc{0}.
\]
    Последнее равенство можно переписать в следующем виде:
\begin{equation}\label{razloj-grad-vip}
    \nabla f(\vc{\hat{x}})=
    \hat p_1 \nabla g_1(\vc{\hat{x}})+ \ldots + \hat p_m \nabla g_m(\vc{\hat{x}}).
\end{equation}
    Это позволяет нам заключить, что справедлива следующая версия
    теоремы Куна-Таккера.

\begin{teop}\label{Kuhn-T-Vip5}(Теорема Куна-Таккера)

    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPleq}) выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}$, принадлежащая внутренности
    множества $\st{X}$, в которой непрерывно дифференцируемы
    как целевая функция $f(\vc{x})$, так и функции $g_{j}(\vc{x}), \
    j=1,\ldots,m,$ представляет собой решение
    задачи~(\ref{problem:ZVPleq}) тогда и только тогда, когда существуют такие
    неотрицательные коэффициенты $\hat p_1, \hat p_2 \ldots, \hat p_m$,
    что выполняются равенство (\ref{razloj-grad-vip}) и
    условия дополняющей нежесткости (\ref{dop-nezj-vp1}).
\end{teop}


    В сформулированной теореме важную роль играет то, что
    рассматриваемая точка $\vc{\hat x}$ лежит во внутренности
    множества $\st{X}$. Если в качестве этого множества выступает
    все пространство $\R^{n}$, то любая его точка является
    внутренней. Если же взять $\st{X}=\R^{n}_{+}$, то вполне возможно, что
    решение задачи окажется на границе $\R^{n}_{+}$ и, формально
    говоря, непосредственное применение данной теоремы может
    оказаться бесполезным. В то же время, очевидно, справедлива
    следующая ее модификация.

\begin{teop}\label{Kuhn-T-Vip6}(Теорема Куна-Таккера)
    Предположим, что для задачи выпуклого программирования
    (\ref{problem:ZVPleq}) в качестве множества $\st{X}$ выступает
    $\R^{n}_{+}$ и выполняется условие Слейтера.
    Допустимая точка $\vc{\hat x}$, в которой непрерывно дифференцируемы
    как целевая функция $f(\vc{x})$, так и функции $g_{j}(\vc{x}), \
    j=1,\ldots,m,$ представляет собой решение
    задачи~(\ref{problem:ZVPleq}) тогда и только тогда, когда существуют такие
    неотрицательные коэффициенты $\hat p_1, \hat p_2 \ldots, \hat p_m$,
    что выполняются соотношения
\[
    \nabla f(\vc{\hat{x}})\leqq
    \hat p_1 \nabla g_1(\vc{\hat{x}})+ \ldots + \hat p_m \nabla g_m(\vc{\hat{x}}),
\]
\[
    (\hat p_1 \nabla g_1(\vc{\hat{x}})+ \ldots + \hat p_m \nabla g_m(\vc{\hat{x}})
    -\nabla f(\vc{\hat{x}})\vc{\hat{x}}=0,
\]
    а также условия дополняющей нежесткости (\ref{dop-nezj-vp1}).
\end{teop}

    Здесь нужно иметь в виду, что в этой теореме мы неявно
    предполагаем, что функция $f(\vc{x})$ определена на некотором
    выпуклом множестве, содержащем $\R^{n}_{+}$, причем по отношению к этому множеству
    точка $\vc{\hat x}$ является внутренней. Действительно, чтобы
    говорить о дифференцируемости функции в некоторой точке, нужно
    быть уверенным в том, что эта функция определена в некоторой окрестности
    рассматриваемой точки.




    Задача линейного программирования являются частным случаем задачи выпуклого
    программирования. Поэтому можно ожидать, что теория необходимых
    и достаточных условий оптимальности, разработанная нами в главе
    ????, должна достаточно просто вытекать из теоремы Куна-Таккера
    для задачи выпуклого программирования. Это ожидание в
    значительной мере, хотя и с некоторыми оговорками, обоснованно,
    о чем и говорит следующее упражнение, в котором мы простоты ради ограничиваем
    наше рассмотрение только стандартной задачей линейного
    программирования.

    \begin{exer}
    Рассмотрим стандартную задачу линейного программирования:
\begin{equation}\label{SZLPV-1}
    \left\{
    \begin{array}{rl}
        \vc{c} \, \vc{x} & \to \max  \\
        \vc{A} \vc{x} &\leqq \vc{b} \\
        \vc{x} &\geqq \vc{0}\\
    \end{array} \right.
\end{equation}
    С помощью теоремы \ref{Kuhn-T-Vip4} выведите для этой задачи
    утверждение теоремы двойственности (предложения
    \ref{teor-dv-st}) в предположении, что задача удовлетворяет
    условию
    Слейтера, т.е. существует вектор $\vc{\bar{x}} \geqq \vc{0}$,
    обладающий тем свойством, что $\vc{A} \vc{\bar{x}} \ll \vc{b}$.
\end{exer}

    Как мы помним, утверждение теоремы двойственности верно для
    задачи (\ref{SZLPV-1}) и  без условия Слейтера. В то же время,
    во всех формулировках
    теоремы  Куна-Таккера, которые мы здесь привели, это условие
    является существенным. Отметим, однако, что его в
    задаче выпуклого программирования можно ослабить до такой
    степени, что утверждение теоремы
    Куна-Таккера останется верным, а теоремы двойственности для
    линейного программирования будут из этой теоремы вытекать во всей их
    общности, хотя мы этим заниматься не будем.


    \begin{exer}
    Рассмотрим стандартную задачу линейного программирования:
\begin{equation}\label{SZLPV-1}
    \left\{
    \begin{array}{rl}
        \vc{c} \, \vc{x} & \to \max  \\
        \vc{A} \vc{x} &\leqq \vc{b} \\
    \end{array} \right.
\end{equation}
    С помощью теоремы \ref{Kuhn-T-Vip5} выведите для этой задачи
    утверждение предложения
    \ref{PSZLPV-usl-opt} в предположении, что задача удовлетворяет
    условию
    Слейтера, т.е. существует вектор $\vc{\bar{x}}\in\R^{n}$,
    обладающий тем свойством, что $\vc{A} \vc{\bar{x}} \ll \vc{b}$.
\end{exer}


    Формулировку теоремы \ref{Kuhn-T-Vip5} интересно сравнить с
    формулировкой теоремы \ref{np-mno-la}. Обе эти теоремы говорят о
    том, что при некоторых предположениях, называемых  условиями регулярности,
    в точке решения задачи на
    условный максимум градиент целевой функции разлагается в
    линейную комбинацию градиентов функций, задающих ограничения,
    и выполняются условия дополняющей нежесткости. В
    случае, когда речь идет о задаче, которая не является, вообще
    говоря, задачей выпуклого программирования, условием
    регулярности является требование о том, что набор
    вектор-градиентов тех функций $g_{j}(\vc{x})$, которые
    соответствуют активным ограничения, является линейно независимы.
    В случае задачи выпуклого программирования условием регулярности
    является условие Слейтера. При этом в случае задачи выпуклого
    программирования формулируемые условия оптимальности являются не
    только необходимыми, но и достаточными.

    В связи с этом естественно возникает предположение о том, что
    возможны и другие интересные для экономической теории варианты условий
    регулярности, а также возможны предположения, при которых
    соответствующие условия являются не только необходимыми, но и
    достаточными. До некоторой степени это предположение является
    обоснованным, о чем говорят следующая теорема, которую
    мы приведем без доказательства.

    Рассмотрим задачу
\begin{equation}\label{problem:ZCVPleq}
    \left\{ \begin{array}{l}
         f(\vc{x}) \to \max  \\
        g_j (\vc{x}) \leqslant b_j, \ j = 1,\ldots,m,\\
        \vc{x} \in \st{X}, \\
  \end{array} \right.
\end{equation}
    в предположении, что множество $\st{X}$ выпукло, целевая функция
    $f(\vc{x})$ квазивогнута, а функции $g_j (\vc{x}), \ j =
    1,\ldots,m,$ квазивыпуклы.

\begin{teop}\label{Kuhn-T-quasi-Vip}
    Предположим, что во внутренней точке $\vc{\hat{x}}$ множества
    $\st{X}$ функции $f(\vc{x})$ и
    $g_j (\vc{x}), j=1,\ldots,m,$ непрерывно дифференцируемы.

    1. Если задача (\ref{problem:ZCVPleq}) удовлетворяет
    условию Слейтера, т.е. существует такая точка
    $\vc{\bar{x}}\in\st{X}$, что
    $g_j (\vc{\bar{x}})<b_{j}, \  j=1,\ldots,m,$ а
    точка $\vc{\hat{x}}$ представляет собой решение этой задачи,
    причем в этой точке градиенты всех функций, задающих активные
    ограничения, не равны нулю
    $(g_{j}(\vc{\hat{x}})=b_{j} \Rightarrow \nabla  g_{j}(\vc{\hat{x}})\neq\vc{0}),$
    то существуют такие неотрицательные числа $\hat p_1, \hat p_2 \ldots, \hat
    p_m$, что выполняются равенство
\[
    \nabla f(\vc{\hat{x}})=
    \hat p_1 \nabla g_1(\vc{\hat{x}})+ \ldots + \hat p_m \nabla g_m(\vc{\hat{x}})
\]
    и условия дополняющей нежесткости
\[
    \hat p_j \,(b_j-g_j(\vc{\hat x}))=0, \ j=1,\ldots,m.
\]

    2. Если для точки $\vc{\hat x}$, такой что $f(\vc{\hat{x}})\neq\vc{0}$, и
    неотрицательных чисел $\hat p_1, \hat p_2, \ldots, \hat p_m$
    выполняются  два последних соотношения, то точка $\vc{\hat x}$ представляет
    собой решение задачи (\ref{problem:ZCVPleq}).
\end{teop}


\subsection{Оптимальное распределение ресурсов и равновесие}

    В параграфе ??????
        мы начали изучение оптимизационных задач с рассмотрения
    простейшей задачи распределения ресурса. Сейчас мы на основе
    теоремы Куна-Таккера обобщим проведенный там анализ на случай,
    когда распределяется несколько различных видов ресурсов. Наша
    цель состоит в том, чтобы обобщить интерпретацию множителей Лагранжа
    в задаче распределения ресурсов как цен равновесия и на этот случай.

    Итак, рассмотрим большую фирму, состоящую из $r$ предприятий.
    Технологические возможности предприятия $s=1,\ldots,r$
    описываются производственной функцией
    $F_{s}(\vc{x})=F(x_{1},\ldots,x_{m})$,
    показывающей объем выпуска продукции в денежном выражении в
    зависимости от затрат различных видов ресурсов, с
    первого по $m$-й. Про каждую производственную функцию $F_{s}(\vc{x})$ предполагается,
    что она задана и непрерывна на $\R^{m}_{+}$, что она вогнута и монотонно
    возрастает ($\vc{x''}\gg\vc{x'}\Rightarrow
    F_{s}(\vc{x''})>F_{s}(\vc{x'})$).

    Если в распоряжении у фирмы имеется вектор ресурсов
    $\vc{b}=(b_{1},\ldots,b_{m})\gg\vc{0}$, то задача оптимального
    распределения этих ресурсов состоит в том, чтобы распределить
    их между предприятиями с тем, чтобы максимизировать суммарный
    выпуск. Она записывается следующим естественным образом:
\begin{equation}
    \label{rasp-nesk-res}
    \begin{array}{c}
      F_{1}(\vc{x_{1}})+\ldots+F_{r}(\vc{x_{r}})\rightarrow \max, \\
      \vc{x_{1}}+\ldots+\vc{x_{r}}\leqq\vc{b}, \\
      \vc{x_{1}}\geqq\vc{0},\ldots,\vc{x_{r}}\geqq\vc{0},
    \end{array}
\end{equation}
    где $\vc{x_{s}}$ --- вектор ресурсов, который достается $s$-му
    предприятию.

    Под \emph{оптимальным распределением} ресурсов мы будем понимать набор
    векторов $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$, составляющих
    решение задачи (\ref{rasp-nesk-res}).

    Наряду с оптимальным распределением ресурсов, как и в параграфе
    ???? можно рассмотреть равновесное их распределение между
    предприятиями. Для того, чтобы ввести понятие равновесия на
    рынке распределяемых ресурсов, предположим, что при каждом
    заданном неотрицательном векторе цен
    $\vc{p}=(p_{1},\ldots,p_{m})$ каждое предприятие $s$ решает
    условную задачу максимизации прибыли:
\begin{equation}
    \label{rasp-nesk-res-max-prib}
    F_{s}(\vc{x})-\vc{p}\vc{x}\rightarrow\max, \ \vc{x}\geqq\vc{0}.
\end{equation}
    Решение этой задачи мы можем рассматривать как спрос предприятия $s$ на
    распределяемые ресурсы в зависимости от их цен. Правда, здесь
    надо учитывать, что это решение может быть неединственным.

    По поводу задачи о максимизации прибыли (\ref{rasp-nesk-res-max-prib})
    нужно заметить, что при ее решении предприятие $s$ ведет себя
    как совершенный конкурент в том смысле, что воспринимает вектор
    цен на ресурсы $\vc{p}$ как экзогенно заданные.


    Под \emph{состоянием равновесия} на рынке распределяемых
    ресурсов мы будем понимать набор векторов
    $\{\vc{p^{*}}, (\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})\}$,
    состоящий из вектора равновесных цен $\vc{p^{*}}\geqq\vc{0}$ и
    совокупности векторов $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$
    равновесного распределения ресурсов, удовлетворяющий следующим
    условиям:
\begin{enumerate}
  \item для всех $s=1,\ldots,r$ вектор $\vc{x_{s}^{*}}$ является
    решением задачи (\ref{rasp-nesk-res-max-prib}) при
    $\vc{p}=\vc{p^{*}}$;
  \item $\vc{x_{1}^{*}}+\ldots+\vc{x_{r}^{*}}\leqq\vc{b}$;
  \item
  $\vc{p^{*}}(\vc{b}-(\vc{x_{1}^{*}}+\ldots+\vc{x_{r}^{*}}))=0$.
\end{enumerate}


    В этом определении условие 1) говорит о том, что каждое
    предприятие решает задачу о максимизации прибыли, условие 2) ---
    о том, что суммарный спрос со стороны всех предприятий не должен
    превосходить суммарного предложения, представленного вектором
    $\vc{b}$, а условие 3) --- что цена того ресурса, суммарный спрос на который
    строго меньше предложения, должна равняться нулю.

    Читатель, знакомый с рассуждениями из параграфа ??? уже, несомненно, заметил,
    что оптимальное и равновесное распределение ресурсов суть одно и
    то же, а вектор множителей Лагранжа, соответствующих ограничения на
    ресурсы, представляет собой вектор равновесных цен.
     Действительно, имеет место следующее предложение.
\begin{prop}\label{opt=ravn}
    Набор $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$ представляет
    собой оптимальное распределение ресурсов тогда и только тогда,
    когда существует такой вектор равновесных цен
    $\vc{p^{*}}\geqq\vc{0}$, что набор
    $\{\vc{p^{*}}, (\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})\}$
    является состоянием равновесия. Требуемым вектором равновесных
    цен является вектор коэффициентов Куна-Таккера в задаче
    (\ref{rasp-nesk-res}).
\end{prop}
    \emph{\textbf{Доказательство.}}  По теореме Куна-Таккера набор
    векторов $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$ представляет
    собой оптимальное распределение ресурсов тогда и только тогда,
    когда существует такой вектор равновесных цен
    $\vc{p^{*}}\geqq\vc{0}$, что
    \begin{enumerate}
  \item $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$ является
    решением задачи
\begin{multline}\label{max-summy}
    F_{1}(\vc{x_{1}})+\ldots+F_{r}(\vc{x_{r}})
    -\vc{p^{*}}(\vc{x_{1}}+\ldots+\vc{x_{r}})
    \rightarrow \max,
    \\ \vc{x_{1}}\geqq\vc{0},\ldots,\vc{x_{r}}\geqq\vc{0};
\end{multline}
  \item $\vc{x_{1}^{*}}+\ldots+\vc{x_{r}^{*}}\leqq\vc{b}$;
  \item
  $\vc{p^{*}}(\vc{b}-(\vc{x_{1}^{*}}+\ldots+\vc{x_{r}^{*}}))=0$.
\end{enumerate}
    Поскольку
\begin{multline*}
    F_{1}(\vc{x_{1}})+\ldots+F_{r}(\vc{x_{r}})
    -\vc{p^{*}}(\vc{x_{1}}+\ldots+\vc{x_{r}})= \\
    =(F_{1}(\vc{x_{1}})-\vc{p^{*}}\vc{x_{1}})+\ldots+(F_{r}(\vc{x_{r}})-\vc{p^{*}}\vc{x_{r}}),
    \ \forall \vc{x_{1}},\ldots,\vc{x_{r}}\in\R^{m}_{+},
\end{multline*}
    задачу (\ref{max-summy}) можно переписать в следующем виде:
\begin{multline}\label{max-summy-1}
    (F_{1}(\vc{x_{1}})-\vc{p^{*}}\vc{x_{1}})+\ldots+(F_{r}(\vc{x_{r}})-\vc{p^{*}}\vc{x_{r}})
    \rightarrow \max,
    \\ \vc{x_{1}}\geqq\vc{0},\ldots,\vc{x_{r}}\geqq\vc{0}.
\end{multline}
    Это задача о максимизации некоторой суммы, слагаемые которой
    никак между собой не связаны. Поэтому для ее решения достаточно
    каждое слагаемое по отдельности. Иными словами,
    $(\vc{x_{1}^{*}},\ldots,\vc{x_{r}^{*}})$ является решением
    задачи (\ref{max-summy}) тогда и только тогда, когда для всех
    $s=1,\ldots,r$ вектор $\vc{x_{s}^{*}}$ является при $\vc{p}=\vc{p^{*}}$ решением задачи
    (\ref{rasp-nesk-res-max-prib}). $\Box$




\subsection{Оптимальное распределение ресурсов и экономическая прибыль}

    Один важный частный случай задачи (\ref{rasp-nesk-res}) является
    очень важным и заслуживает особого внимания. А именно, тот случай,
    когда все производственные функции $F_{s}(\vc{x}), \ s=1,\ldots,r,$ являются положительно
    однородными первой степени, т.е. удовлетворяющие равенству
\[
    F_{s}(\lambda\vc{x})=\lambda F_{s}(\vc{x}), \lambda\geqslant0,
    \vc{x}\geqq\vc{0}.
\]
    Как мы помним, в таком случае говорят, что производственная
    функция  удовлетворяет свойству постоянной отдачи от расширения
    масштаба производства.

    Рассмотрим задачу (\ref{rasp-nesk-res-max-prib}) в
    предположении, что $F_{s}(\vc{x})$ удовлетворяет этому свойству.
    Возможны три качественно различных случая.
\begin{enumerate}
  \item $F_{s}(\vc{x})<\vc{p}\vc{x}$ для любого
  $\vc{x}$, при котором $F_{s}(\vc{x})>0$. В этом случае решением рассматриваемой задачи
  являются только вектора $\vc{x}$, для которых $F_{s}(\vc{x})=0$ и, следовательно, $\vc{p}\vc{x}=0$.
  \item Существует ненулевой вектор $\vc{\hat{x}}$, для которого
  выполняется неравенство $F_{s}(\vc{\hat{x}})>\vc{p}\vc{\hat{x}}$.
  В этом случае у задачи решения просто нет, ибо при выборе
  достаточно большого $\lambda>0$ мы можем получить сколь угодно
  большое значение целевой функции
  $F_{s}(\lambda\vc{\hat{x}})-\vc{p}(\lambda\vc{\hat{x}})$ в точке $\lambda\vc{\hat{x}}$.
  \item $F_{s}(\vc{x})\leqslant\vc{p}\vc{x}$ для любого
  $\vc{x}\geqq\vc{0}$, но при этом существует  вектор $\vc{\hat{x}}$, для которого
  $F_{s}(\vc{\hat{x}})=\vc{p}\vc{\hat{x}}>0$. В этом случае решением
  задачи является как сам вектор $\vc{\hat{x}}$, так и любой вектор
  вида $\lambda\vc{\hat{x}}$ при $\lambda\geqslant0$, т.е. всякий
  вектор, лежащий на луче, выходящем из нулевого вектора и
  проходящем через $\vc{\hat{x}}$.
\end{enumerate}

\begin{exer}
    Введем в рассмотрение функцию удельных затрат $c_{s}(\vc{p})$,
    заданную на $\R^{m}_{+}$ и определяему посредством равенства
\[
    c_{s}(\vc{p})=\inf\{\vc{p}\vc{x}\mid F_{s}(\vc{x})
    \leqslant 1\}.
\]
    Покажите, что случай 1) выполняется тогда и только тогда, когда
    $c_{s}(\vc{p})>1$, случай 2) --- тогда и только тогда, когда
    $c_{s}(\vc{p})<1$, и случай 3) --- тогда и только тогда, когда
    $c_{s}(\vc{p})=1$.
\end{exer}

    С содержательной точки в первом случае невозможно, чтобы
    положительный объем выпуска окупался.
    Поэтому в том плане, который обеспечивает предприятию
    максимальную прибыль производиться ничего не будет.

    Второй случай характеризуется тем, что производство
    может не только окупаться, но и приносить положительную прибыль.
    Тем самым это производство выгодно просто увеличивать до
    бесконечности.

    В третьем случае
    положительный выпуск окупается при некотором выборе вектора
    затрат, но невозможна ситуация, когда выпуск продукции приносит
    положительную прибыль. В силу постоянной отдачи от расширения
    масштаба производства в этом случае окупаться может любой
    сколь угодно большой объем выпуска.

    В ситуации, когда речь идет о равновесных ценах
    $\vc{p}=\vc{p^{*}}$, для любого предприятия может реализоваться
    только первый или третий случай. Тем самым, в состоянии равновесия
    множество всех предприятий делится на две группы. К первой
    группе относятся те предприятия, на которых при равновесных
    ценах на ресурсы положительный объем выпуска может окупаться, а
    ко второй те, на которых положительный выпуск не окупиться ни
    при каком выборе вектора затрат (эта вторая группа может и не
    содержать ни одного предприятия). Выпускаться продукция в
    состоянии равновесия будет только на предприятиях первой группы,
    хотя и среди них могут оказаться те, для которых выпуск равен
    нулю. При этом ни на одном из предприятий прибыль не может быть
    положительной.

    Тем самым \emph{суммарная прибыль всех предприятий в
    состоянии равновесия равна нулю}. С такой ситуацией мы уже
    встречались, когда рассматривали линейную задачу распределения
    ресурсов и, формально говоря, возникает из-за предположения о
    постоянной отдачи от расширения масштаба производства.

    На первый взгляд она кажется довольно удивительной, поскольку в
    реальной жизни прибыль не равна нулю. Быть может, дело в том, что
    не очень адекватно именно предположение о постоянной отдаче от
    расширения масштаба производства? Быть может, более реалистичным было бы
    предположение об убывающей отдаче? Ведь в этом втором случае прибыль
    предприятий в состоянии равновесия будет положительной.

    Сейчас мы попытаемся объяснить, в чем же тут дело. А дело в том,
    что в рассматриваемой модели отсутствует такая важная
    переменная, как время. Нам следует вспомнить, что прибыль ---
    это величина, которая имеет размерность потока. Прибыль можно
    получить только за некоторый нулевой промежуток времени. А в нашей
    модели этого промежутка как раз и нет. В ее рамках затраты
    $\vc{p}\vc{x}$ в денежном выражении и
    доход $F_{s}(\vc{x})$, получаемый от продажи выпущенной продукции,
    относятся к одному и тому же моменту
    времени. Поэтому положительной прибыли и быть не может.
    Получение положительной прибыли  в процессе
    производства за нулевой промежуток
    времени --- это, надо думать, несбыточная мечта. Быть может,
    экономически образованный читатель вспомнит понятие
    <<арбитраж>>, но оно относится к тому классу явлений
    экономической, точнее, финансовой, жизни, которые имеют явно неравновесный характер.

    Если же в явном виде учитывать тот факт, что затраты и выпуск
    разделены во времени, то можно рассуждать, например, следующим
    образом. Предположим, что все затраты $\vc{x}$ осуществляются
    единовременно, а доход $F_{s}(\vc{x})$ от  производства и
    реализации выпущенной продукции получается ровно через один
    промежуток времени. Тот факт, что затраты и выпуск разнесены во
    времени, совсем не означает, что в выражении
    $F_{s}(\vc{x})-\vc{p}\vc{x}$ соизмеряемые величины
    $F_{s}(\vc{x})$ и $\vc{p}\vc{x}$ относятся к разным моментам
    времени. Величина $p_{i}$ --- это такая цена за $1$ единицу  $i$-го ресурса,
    с помощью которой предприятие эту единицу в момент выпуска и
    реализации продукции, т.е. в конце производственного цикла,
    хотя
    затрачивается эта единица ресурса предприятием в самом
    начале производственного цикла. Тем самым
    использование вектора ресурсов $\vc{x}$ и его оценка в
    размере $\vc{p}\vc{x}$ тоже разнесены во
    времени, причем оценка относится к тому же моменту, что и
    получение дохода $F_{s}(\vc{x})$. Эта оценка включает в себя то,
    что экономисты называют альтернативные издержки или издержки
    неиспользованных возможностей (opportunity costs).

    Разность между доходами предприятия и его затратами,
    включающими альтернативные издержки называют в экономической
    литературе эту величину  \emph{экономической
    прибылью}, чтобы отличить ее от прибыли в обычном смысле этого
    слова, т.е. от прибыли в бухгалтерском смысле. Те из читателей,
    кто внимательно читал учебники по микроэкономике, видимо,
    встречал там понятие экономической прибыли и даже указание
    на то, что целью производителя является не бухгалтерская, а
    экономическая прибыль, и что
    в состоянии долгосрочного равновесия она равна нулю.
    И в нашей модели, если интерпретировать величина
    $F_{s}(\vc{x})-\vc{p}\vc{x}$ как экономическую прибыль,
    тот факт, что в состоянии равновесия она
    оказывается равной нулю, уже нет ничего удивительного.

    Равенству нулю экономической прибыли не означает, что
    бухгалтерская прибыль тоже равна нулю, хотя чему она равна, мы
    сказать не можем. Для того чтобы прояснить ситуацию в рамках нашей модели,
    предположим, что единственным альтернативным способом
    использования любого из ресурсов является его продажа (в начале производственного
    цикла) и вложение средств от продажи в банк по ставке $r\%$. В
    этом случае соотношение между равновесной ценой $p_{j}^{*}$ каждого ресурса
    $j=1,\ldots,m$, включающей альтернативные издержки, и его ценой
    $p_{j}^{0}$, их не включающей, должно удовлетворять соотношению
\[
    p_{j}^{*}=(1+r)p_{j}^{0},
\]
    или, что то же,
\[
        p_{j}^{0}=\frac{p^{*}_{j}}{(1+r)}.
\]
    Эти равенства говорят о то, что если за поставку в начале производственного $1$
    единицы ресурса $j$ в момент поставки надо заплатить $p_{j}^{0}$
    денежных единиц, то, если момент оплаты переносится на конец
    производственного цикла, заплатить придется
    $p_{j}^{*}=(1+r)p_{j}^{0}$ денежных единиц.



    Мы видим, что если вектор $\vc{x_{s}^{*}}$ представляет собой
    решение задачи
\[
    F_{s}(\vc{x})-\vc{p^{*}}\vc{x}\rightarrow\max, \ \vc{x}\geqq\vc{0},
\]
    о максимизации предприятием $s$ экономической прибыли при равновесных ценах,
    то бухгалтерская прибыль $\Pi(\vc{x_{s}^{*}})$ этого предприятия
    в точке $\vc{x_{s}^{*}}$ равна
$\Pi(\vc{x^{*}})=F_{s}(\vc{x_{s}^{*}})-\vc{p^{0}}\vc{x_{s}^{*}}$,
    где $\vc{p^{0}}=(p_{1}^{0},\ldots,p_{m}^{0})$.
    Поскольку $\vc{p^{0}}=\frac{\vc{p^{*}}}{1+r}$, мы имеем:
\[
    \Pi(\vc{x_{s}^{*}})=F_{s}(\vc{x_{s}^{*}})-\frac{\vc{p^{*}}}{1+r}\vc{x_{s}^{*}}.
\]

    Нам осталось заметить, что поскольку мы рассматриваем случай,
    когда производственная функция демонстрирует постоянную отдачу
    от расширения масштаба производства,
    $F_{s}(\vc{x_{s}^{*}})=\vc{p^{*}}\vc{x_{s}^{*}}$.
    Следовательно,
\[
    \Pi(\vc{x_{s}^{*}})=r\vc{p^{0}}\vc{x_{s}^{*}}.
\]
    Здесь нужно еще раз напомнить, что, в отличие от вектора цен
    $\vc{p^{*}}$, включающих альтернативные издержки, вектор цен
    $\vc{p^{0}}$ их не включает и предназначен для оценки вектора
    используемых ресурсов на момент начала производственного цикла.
    Значит последнее равенство говорит нам о том, что если выпуск
    $F_{s}(\vc{x_{s}^{*}})$ предприятия $s$ положителен, то вложения
    этого предприятия в ресурсы в точке $\vc{x_{s}^{*}}$ обеспечивают
    прибыльность (норму прибыли) за период, совпадающий
    с длительность производственного цикла,
    равную ставке процента $r$. Очевидно, ни
    при каком другом векторе затрат $\vc{x}$ прибыльность не может
    превосходить ставку процента. Если для
    некоторого предприятия $s$ никакой вектор затрат $\vc{x}$, дающий
    положительный выпуск $F_{s}(\vc{x})$, не может при векторе цен $\vc{p^{0}}$
    на ресурсы обеспечить прибыльность $r$, т.е. если
\[
    F_{s}(\vc{x})>0 \Rightarrow
    F_{s}(\vc{x})<(1+r)\vc{p^{0}}\vc{x},
\]
    то в состоянии равновесия выпуск этого предприятия равен нулю.

    Итак, мы видим, что если производственные функции удовлетворяют
    свойству постоянной отдачи от расширения масштаба производства,
    то в состоянии равновесия экономическая прибыль каждого
    предприятия равна нулю, но это не означает, что нулю равняется
    бухгалтерская прибыль.

\begin{exer}
    В предположении, что все производственные функции
    $F_{s}(\vc{x})$ демонстрируют постоянную отдачу от расширения
    масштаба производства и что единственным альтернативным способом
    использования любого из ресурсов является его продажа (в начале производственного
    цикла) и вложение средств от продажи в банк по ставке $r\%$,
    введите понятие равновесия, в котором упоминаются только цены, не включающие
    альтернативные издержки.
    Переформулируйте для такого контекста предложение
    \ref{opt=ravn}.
\end{exer}





\begin{exer}
    Рассмотрим следующую стандартную задачу линейного
    программирования, которую
    естественно интерпретировать  как линейную задачу распределения
    ресурсов:
\begin{equation} \label{SZLP-exer}
\left\{
\begin{array}{rrrrllll}
     c_1 x_1 + & c_2 x_2 +    & \ldots +& c_r x_r &\to & \max\\
     a_{11} x_1 + & a_{12} x_2 + &\ldots +& a_{1r} x_r &\leqslant& b_1 \\
     a_{21} x_1 + & a_{22} x_2 + &\ldots +& a_{2r} x_r &\leqslant& b_2\\
                      & \ldots &&&&\\
     a_{m1} x_1 + & a_{m2} x_2 +& \ldots +& a_{mr} x_r &\leqslant& b_m\\
     x_1 \geqslant 0,   & x_2 \geqslant 0,  & \ldots,&  x_r \geqslant 0\\
\end{array} \right.
\end{equation}
    и предположим, что $c_{s}>0, s=1,\ldots,r,$ и $b>0, j=1,\ldots,m$, а
    также, что $a_{js}\geqslant0, j=1,\ldots,m, s=1,\ldots,r,$
    причем $\max\{a_{1s},\ldots,a_{ms}\}>0, s=1,\ldots,r$.
    Определим производственные функции
    $F_{s}(\vc{x})=F_{s}(x_{1},\ldots,x_{m})$,
    заданные на $\R_{+}^{m}$, посредством равенств
\[
    F_{s}(\vc{x})=\min\{\frac{x_{1}}{a_{1s}},\ldots,\frac{x_{m}}{a_{ms}}\}
    =\max\{\lambda\mid\lambda\vc{x}\leqq\vc{a_{s}}\},
    s=1,\ldots,r,
\]
    где $\vc{a_{s}}=\left(
                      \begin{array}{c}
                        a_{1s} \\
                        \vdots \\
                        a_{ms} \\
                      \end{array}
                    \right)
    $
    --- это $s$-й столбец $m\times r$ матрицы, состоящей из чисел
    $a_{js}\geqslant0, j=1,\ldots,m, s=1,\ldots,r,$
    и рассмотрим при $\vc{b}=\left(
                                         \begin{array}{c}
                                           b_{1} \\
                                           \vdots \\
                                           b_{m} \\
                                         \end{array}
                                       \right).    $
    задачу (\ref{SZLP-exer}).
    Покажите, как по решению из двух задач, (\ref{SZLP-exer})
    или (\ref{rasp-nesk-res}), найти
    решение второй и докажите, что двойственные оценки в обеих
    задачах совпадают.
\end{exer}


    Если читатель согласился с доводами о том, что в состоянии
    равновесия экономическая прибыль должна равняться нулю, у него
    должен возникнуть естественный вопрос о том, как же
    интерпретировать ситуацию, когда в состоянии равновесия прибыль
    какого-то предприятия окажется положительной величиной. Именно
    такая ситуация скорее всего сложится, если производственная
    функция какого-то
    предприятия демонстрирует убывающую отдачу от расширения
    масштаба производства.

    Однако, здесь нет ничего противоречащего нашим рассуждениям.
    Предположим, что для некоторого предприятия, из которых состоит
    фирма, для которой необходимо решить задачу (\ref{rasp-nesk-res}),
    например, для предприятия $s$,  производственная функция
    $F_{s}(\vc{x})$
     обладает свойством убывающей отдачи от
    расширения масштаба производства. В этом случае, действительно,
    если в точке $\vc{x^{*}}$ решения задачи
\[
    F_{s}(\vc{x})-\vc{p}\vc{x}\rightarrow\max, \ \vc{x}\geqq\vc{0},
\]
    объем выпуска положителен, т.е. $F_{s}(\vc{x^{*}})>0$, то и
    прибыль этого предприятия в данной точке тоже положительна:
\[
    F_{s}(\vc{x^{*}})-\vc{p}\vc{x^{*}}>0.
\]
\begin{exer}
    Докажите справедливость последнего утверждения.
\end{exer}
    Однако, здесь следует вспомнить наши рассуждения из параграфа
    ?????, посвященного производственным функциям. Тот факт, что
    производственная функция $F_{s}(\vc{x})$ демонстрирует убывающую
    отдачу от расширения масштаба производства, естественно
    интерпретировать как свидетельство того, что среди существенных
    факторов производства на предприятии $s$ есть такие, которые не
    включены в число аргументов производственной функции
    $F_{s}(\vc{x})$.

    Предположим, что полный перечень всех существенных
    факторов производства на рассматриваемом предприятии состоит из
    $k>n$ различных видов ресурсов.
     Тем самым, можно считать, что его <<настоящая>>
    производственная функция $\tilde{F}_{s}(\vc{z})=\tilde{F}_{s}(\vc{x},\vc{y})$ определена на
    $\R^{k}_{+}$. Здесь $\vc{z}$ --- это вектор затрат всех
    существенных ресурсов. Этот вектор имеет вид
    $\vc{z}=(\vc{x},\vc{y})$, где $\vc{y}\in\R^{k-n}_{+}$ --- вектор
    затрат тех ресурсов, которые не включены в число аргументов функции
    $F_{s}(\vc{x})$. При этом использование именно последней функции при
    рассмотрении задачи распределения ресурсов (\ref{rasp-nesk-res})
    вполне оправдано, поскольку при ее решении
    предполагается, что $\vc{y}=\vc{\bar{y}}$, где
    $\vc{\bar{y}}\gg\vc{0}$  --- некоторый зафиксированный вектор.
    Так что естественно вместо функции
    $\tilde{F}_{s}(\vc{z})=\tilde{F}_{s}(\vc{x},\vc{y})$
    естественно использовать функцию $F_{s}(\vc{x})$, предполагая
    что эта последняя задается равенством
\[
    F_{s}(\vc{x})=\tilde{F}_{s}(\vc{x},\vc{\bar{y}}).
\]

    При этом следует помнить, что с учетом сказанного величину
\[
    F_{s}(\vc{x})-\vc{p}\vc{x}=\tilde{F}_{s}(\vc{x},\vc{\bar{y}})-\vc{p}\vc{x},
\]
    задачу о максимизации которой мы
    хотим назвать задачей о максимизации экономической прибыли,
    называть экономической прибылью в данном случае не совсем
    корректно, поскольку величина $\vc{p}\vc{x}$ не учитывает
    издержки, связанные с той части вектора затрат,
    которая в явном виде игнорируется при использовании функции
    $F_{s}(\vc{x})$, т.е. с вектором $\vc{\bar{y}}$.
    Чтобы корректно учесть эти издержки, необходимо аккуратно
    указать вектор цен с помощью которых следует оценивать
    $\vc{\bar{y}}$. Если в качестве такого вектора  взять
    вектор $\vc{p^{**}}\in\R^{k-n}_{+}$
    двойственных оценок в задаче
\begin{equation}\label{max-pribili-dop}
    \tilde{F}_{s}(\vc{x},\vc{y})-\vc{p}\vc{x}\rightarrow\max,
    \ \vc{y}\leqq\vc{\bar{y}},
    \ \vc{x}\geqq\vc{0}, \ \vc{y}\geqq\vc{0},
\end{equation}
    то, очевидно, экономическая прибыль в точке решения задачи о ее
    максимизации окажется равной нулю.


\begin{exer}
    Пусть вектор $(\vc{x^{*}},\vc{y^{*}})$ представляет собой
    решение задачи (\ref{max-pribili-dop}). Докажите, что если
    $\vc{y^{*}}$ не совпадает с $\vc{\bar{y}}$, то вектор
    $(\vc{x^{*}},\vc{\bar{y}})$ тоже является решением этой задачи.
    Покажите, что если $\vc{p^{**}}\in\R^{k-n}_{+}$ --- это вектор
    двойственных оценок, соответствующих ограничению
    $\vc{y}\leqq\vc{\bar{y}}$, то как $(\vc{x^{*}},\vc{y^{*}})$, так
    и $(\vc{x^{*}},\vc{\bar{y}})$ является решением задачи о
    максимизации экономической прибыли
\[
    \tilde{F}_{s}(\vc{x},\vc{y})-(\vc{p}\vc{x}+\vc{p^{**}}\vc{y})\rightarrow\max,
    \ \vc{x}\geqq\vc{0}, \ \vc{y}\geqq\vc{0},
\]
    и что экономическая прибыль в точке решения равна нулю:
\[
    \tilde{F}_{s}(\vc{x^{*}},\vc{y^{*}})-(\vc{p}\vc{x^{*}}+\vc{p^{**}}\vc{y^{*}})
    =\tilde{F}_{s}(\vc{x^{*}},\vc{\bar{y}})-(\vc{p}\vc{x^{*}}+\vc{p^{**}}\vc{\bar{y}})=0.
\]
\end{exer}































\
